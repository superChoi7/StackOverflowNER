{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IHBeCrOPek7",
    "nbpresent": {
     "id": "71880bb8-62db-43cb-b4a3-b68514ba2d4e"
    }
   },
   "source": [
    "# Named Entity Recognition on Stack Overflow\n",
    "\n",
    "Name: Changheng Liou, Zhiying Cui\n",
    "\n",
    "NetID: cl5533, zc2191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rri7MbidwfcN",
    "nbpresent": {
     "id": "29629440-9fc9-43a6-a4f3-06826bc8dcb1"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "As increasing interest in studying snippets composed of natural languages and computer codes, named entity recognization (NER) for computer programming languages becomes a promising application. \n",
    "\n",
    "Though large numbers of programming texts are readily available on the Internet, there is still a lack of fundamental natural language processing (NLP) techniques for identifying code tokens or software-related named entities that appear within natural language sentences. \n",
    "Another challenge in NER for the computer programming domain is that name entities are often ambiguous. It is hard to refer a word to a technical programming concept or common language. For example, \"list\" not only refers to a data structure but also is used as a variable name. They often have implicit reliance on the accompanied code snippets.\n",
    "\n",
    "[Tabassum et al.](https://arxiv.org/abs/2005.01634) did a comprehensive study in this area. They introduced a new StackOverflow NER corpus for the social computer programming domain, which consists of 15,372 sentences annotated with 20 fine-grained entity types. They proposed a named entity recognizer SoftNER model, which incorporated a context-independent code token classiﬁer with corpus-level features to improve the BERT based tagging model. The evaluation showed that the SoftNER outperforms on identifying software-related named entities than existing models such as fine-tuned BERT, BiLSTEM-CRF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcI7WO6-bxn1",
    "nbpresent": {
     "id": "993b8697-34f5-4ba9-b9df-6b3089cc974d"
    }
   },
   "source": [
    "## Goal of This Work\n",
    "\n",
    "- Identify named entities on software-related texts. Classify them into 20 types of entities.\n",
    "- Evaluate the SoftNER model's performance on other sources of technical articles, such as Leetcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxMcQbbDhI_P"
   },
   "source": [
    "## Development Environmet\n",
    "\n",
    "- Framework: Pythorch\n",
    "- Server: Jupyter server on Google Cloud\n",
    "- Programming environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py36/bin/python\n",
      "3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:09:42) \n",
      "[GCC 7.5.0]\n",
      "sys.version_info(major=3, minor=6, micro=11, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI_TMjMNwlPh",
    "nbpresent": {
     "id": "01b40fdd-08a9-4c27-9ea9-21caa53e3d27"
    }
   },
   "source": [
    "- Directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "├── data\r\n",
      "├── Huggingface_SoftNER\r\n",
      "├── leetcode-discuss.txt\r\n",
      "├── main.ipynb\r\n",
      "├── StackOverflowNER\r\n",
      "└── zipFiles\r\n",
      "\r\n",
      "4 directories, 2 files\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/root/Project/')\n",
    "!tree -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dirProject](./notebook_resources/dirProject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Directory of the SoftNER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "├── code\r\n",
      "│   ├── Attentive_BiLSTM\r\n",
      "│   ├── BERT_NER\r\n",
      "│   ├── DataReader\r\n",
      "│   ├── Readme.md\r\n",
      "│   └── SOTokenizer\r\n",
      "├── License\r\n",
      "├── Readme.md\r\n",
      "└── resources\r\n",
      "    ├── annotated_ner_data\r\n",
      "    └── pretrained_word_vectors\r\n",
      "\r\n",
      "8 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/root/Project/StackOverflowNER')\n",
    "!tree -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dirSoftNER](./notebook_resources/dirSoftNER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLie0qd3eFlX",
    "nbpresent": {
     "id": "382174ac-3857-48ed-bd4a-937463e46433"
    }
   },
   "source": [
    "## Annotated StackOverﬂow Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEluwFCZeTcK",
    "nbpresent": {
     "id": "1a4f0dd7-9e42-41b3-a1ab-14b82991a9b9"
    }
   },
   "source": [
    "### Construction of StackOverﬂow NER corpus\n",
    "\n",
    "Authors introduced a new StackOverflow NER corpus, they\n",
    "- Selected **1,237** question-answer threads from StackOverﬂow 10-year archive (from September 2008 to March 2018).\n",
    "- Manually annotated them with 20 types of entities.\n",
    "    - 8 code entities: CLASS, VARIABLE, IN LINE CODE, FUNCTION, LIBRARY, VALUE, DATA TYPE, HTML XML TAG\n",
    "    - 12 natural language entities: APPLICATION, UI ELEMENT, LANGUAGE, DATA STRUCTURE, ALGORITHM, FILE TYPE, FILE NAME, VERSION, DEVICE, OS, WEBSITE, USER NAME\n",
    "- Corpus was annotated by annotators. Because of the low rate of code-related entities marked by the StackOverﬂow users, and the high possibility of mistakenly enclosed texts that are actually code-related.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2bo3BiSRvQE",
    "nbpresent": {
     "id": "0e904198-95a3-491e-a664-308045b9d783"
    }
   },
   "source": [
    "### StackOverflow tokenizer - SOTokenizer\n",
    "\n",
    "Authors implemented a custom tokenizer `SOTokenizer` for the social computer programming platform, because existing tokenizers, such as CMU Twokenizer, Stanford TweetTokenizer and NLTK Twitter tokenizer all mistakenly split code, for example:\n",
    "\n",
    "```\n",
    "txScope.complete() => [\"txScope\", \".\", \"complete\", \"(\", \")\"]\n",
    "std::condition_variable => [\"std\", \":\", \":\", \"condition_variable\"]\n",
    "math.h => [\"math\", \".\", \"h\"]\n",
    "<html> => [\"<\", \"html\", \">\"]\n",
    "a == b => [\"a\", \"=\", \"=\", \"b\"]\n",
    "```\n",
    "\n",
    "Tokenize sentences with `SOTokenizer`, the results are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1602493738491,
     "user": {
      "displayName": "Chang-Heng Liou",
      "photoUrl": "",
      "userId": "08046120486785659898"
     },
     "user_tz": -480
    },
    "id": "WuNgw9wZR6lG",
    "nbpresent": {
     "id": "99c67626-72eb-4774-b6c5-577237dd8679"
    },
    "outputId": "6935e6e7-d620-4532-817d-9d6ed54d20c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std::condition_variable \n",
      "tokens:  ['std::condition_variable'] \n",
      "\n",
      "I do think that the request I send to my API should be more like {post=>{\"kind\"=>\"GGG\"}} and not {\"kind\"=>\"GGG\"}. \n",
      "tokens:  ['I', 'do', 'think', 'that', 'the', 'request', 'I', 'send', 'to', 'my', 'API', 'should', 'be', 'more', 'like', ' { post=> { \"kind\"=>\"GGG\" }  } ', 'and', 'not', ' { \"kind\"=>\"GGG\" } ', '.'] \n",
      "\n",
      "**Basic idea:** If we start from ```sx,sy```, it will be hard to find ```tx, ty```. If we start from ```tx,ty```, we can find only one path to go back to ```sx, sy```. I cut down one by one at first and I got TLE. So I came up with remainder.  **First line:** if 2 target points are still bigger than 2 starting point, we reduce target points. **Second line:** check if we reduce target points to (x, y+kx) or (x+ky, y)  **Time complexity** I will say ```O(logN)``` where ```N = max(tx,ty)```.  **C++:** ```cpp     bool reachingPoints(int sx, int sy, int tx, int ty) {         while (sx < tx && sy < ty)             if (tx < ty) ty %= tx;             else tx %= ty;         return sx == tx && sy <= ty && (ty - sy) % sx == 0 ||                sy == ty && sx <= tx && (tx - sx) % sy == 0;     } \n",
      "tokens:  ['**', 'Basic', 'idea:**', 'If', 'we', 'start', 'from', '```sx', ',', 'sy```', ',', 'it', 'will', 'be', 'hard', 'to', 'find', '```tx', ',', 'ty```', '.', 'If', 'we', 'start', 'from', '```tx', ',', 'ty```', ',', 'we', 'can', 'find', 'only', 'one', 'path', 'to', 'go', 'back', 'to', '```sx', ',', 'sy```', '.', 'I', 'cut', 'down', 'one', 'by', 'one', 'at', 'first', 'and', 'I', 'got', 'TLE', '.', 'So', 'I', 'came', 'up', 'with', 'remainder', '.', '**', 'First', 'line:**', 'if', '2', 'target', 'points', 'are', 'still', 'bigger', 'than', '2', 'starting', 'point', ',', 'we', 'reduce', 'target', 'points', '.', '**', 'Second', 'line:**', 'check', 'if', 'we', 'reduce', 'target', 'points', 'to', '(', 'x', ',', 'y+kx )', 'or', '(', 'x+ky', ',', 'y )', '**', 'Time', 'complexity**', 'I', 'will', 'say', '```O(logN)```', 'where', '```N', '=', 'max(tx,ty)```.', '**', 'C++', ':**', '```cpp', 'bool', 'reachingPoints(int sx, int sy, int tx, int ty)', '{', 'while', '(', 'sx', '<', 'tx', '&&', 'sy', '<', 'ty )', 'if', '(', 'tx', '<', 'ty )', 'ty', '%', '=', 'tx', ';', 'else', 'tx', '%', '=', 'ty', ';', 'return', 'sx', '==', 'tx', '&&', 'sy', '<=', 'ty', '&&', '(', 'ty', '-', 'sy )', '%', 'sx', '==', '0', '||', 'sy', '==', 'ty', '&&', 'sx', '<=', 'tx', '&&', '(', 'tx', '-', 'sx )', '%', 'sy', '==', '0', ';', '}'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SOTokenizer \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/SOTokenizer')\n",
    "\n",
    "import stokenizer\n",
    "\n",
    "# example 1 - code snippets\n",
    "sentence = 'std::condition_variable'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n",
    "\n",
    "# example 2 - sentences from StackOverflow\n",
    "sentence = 'I do think that the request I send to my API should be more like {post=>{\"kind\"=>\"GGG\"}} and not {\"kind\"=>\"GGG\"}.'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n",
    "\n",
    "# example 3 - sentences from Leetcode (markdown format)\n",
    "sentence = '**Basic idea:** If we start from ```sx,sy```, it will be hard to find ```tx, ty```. If we start from ```tx,ty```, we can find only one path to go back to ```sx, sy```. I cut down one by one at first and I got TLE. So I came up with remainder.  **First line:** if 2 target points are still bigger than 2 starting point, we reduce target points. **Second line:** check if we reduce target points to (x, y+kx) or (x+ky, y)  **Time complexity** I will say ```O(logN)``` where ```N = max(tx,ty)```.  **C++:** ```cpp     bool reachingPoints(int sx, int sy, int tx, int ty) {         while (sx < tx && sy < ty)             if (tx < ty) ty %= tx;             else tx %= ty;         return sx == tx && sy <= ty && (ty - sy) % sx == 0 ||                sy == ty && sx <= tx && (tx - sx) % sy == 0;     }'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkZ66Q-Ra1mt",
    "nbpresent": {
     "id": "10bd16f1-a91c-484a-b154-ed2e670e4d59"
    }
   },
   "source": [
    "### Load annotated files\n",
    "\n",
    "Autours provided a function to read the annotated dataset.\n",
    "- Read the dataset using `loader_so.py` from `DataReader`.\n",
    "- By default the `loader_so_text` function merges the following 6 entities to 3.\n",
    "\n",
    "```\n",
    "\"Library_Function\" -> \"Function\"\n",
    "\"Function_Name\" -> \"Function\"\n",
    "\n",
    "\"Class_Name\" -> \"Class\"\n",
    "\"Library_Class\" -> \"Class\"\n",
    "\n",
    "\"Library_Variable\" -> \"Variable\"\n",
    "\"Variable_Name\" -> \"Variable\"\n",
    "\n",
    "\"Website\" -> \"Website\"\n",
    "\"Organization\" -> \"Website\"\n",
    "```\n",
    "\n",
    "Arguments settings\n",
    "- `merge_tag=False`: skip the merging by setting.\n",
    "- `replace_low_freq_tags=False`: skip the conversion. By default the `loader_so_text` function converts the 5 low frequency entiies as \"O\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 1622,
     "status": "ok",
     "timestamp": 1602420374685,
     "user": {
      "displayName": "Zhiying Cui",
      "photoUrl": "",
      "userId": "00010876004313184189"
     },
     "user_tz": -480
    },
    "id": "NhLsDflQa81v",
    "nbpresent": {
     "id": "faf7cbb1-c9ab-4a20-b0ed-636610af5314"
    },
    "outputId": "7b4a122f-3e5e-49f3-c6d4-b56189841471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "\n",
      "Training dataset (preview first 5 lines):\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'B-Data_Structure']] \n",
      "\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'O']] \n",
      "\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['SQLFIDDLE', 'O', 'B-Application'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "[['SQLFIDDLE', 'O', 'O'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "[['SQLFIDDLE', 'O', 'O'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load annotated data \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/DataReader')\n",
    "\n",
    "import loader_so\n",
    "\n",
    "# dir of dataset\n",
    "path_to_file = \"../../resources/annotated_ner_data/StackOverflow/train.txt\"\n",
    "\n",
    "# merge entities (default)\n",
    "all_sentences = loader_so.loader_so_text(path_to_file)\n",
    "\n",
    "# skip merging\n",
    "all_sentences_no_merge = loader_so.loader_so_text(path_to_file, replace_low_freq_tags= False)\n",
    "\n",
    "# skip conversion\n",
    "all_sentences_no_conversion = loader_so.loader_so_text(path_to_file, replace_low_freq_tags= False)\n",
    "\n",
    "print(\"\\nTraining dataset (preview first 5 lines):\")\n",
    "for i in range(5):\n",
    "    print(all_sentences[i], '\\n')\n",
    "    print(all_sentences_no_merge[i], '\\n')\n",
    "    print(all_sentences_no_conversion[i], '\\n')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A2V27Ujg5Fn",
    "nbpresent": {
     "id": "d1511b90-dbd8-4fc2-a1a5-97b4219de2c6"
    }
   },
   "source": [
    "## SoftNER Model Architecture\n",
    "\n",
    "1. **Input embedding layer**: Extract contextualized embeddings from the BERT model and two new domain-specific embeddings for each word in the input sentence.\n",
    "2. **Embedding attention layer**: Combine the three word embeddings using an attention network.\n",
    "3. **Linear-CRF layer**: Predict the entity type of each word using the attentive word representations from the previous layer.\n",
    "\n",
    "![modelArchitecture](./notebook_resources/modelArchitecture.png)\n",
    "\n",
    "The SoftNER model and two auxiliary models are trained separately. We can train the two standalone modules by the instructions from [Running BERT NER Model](https://github.com/jeniyat/StackOverflowNER/tree/master/code#running-bert-ner-model). Noted that the modified transformers is [here](https://github.com/jeniyat/Huggingface_SoftNER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gobPwiGfg5Fp",
    "nbpresent": {
     "id": "a50d0406-2a0f-4667-ba01-fa7cf49298db"
    }
   },
   "source": [
    "### Input embeddings\n",
    "\n",
    "- **BERT**, which transforms a token into contextual vector representation.\n",
    "- **Code Recognizer**, which represents if a word can be part of a code entity regardless of context.\n",
    "- **Entity Segmenter**, which predicts whether a word is part of any named entity in the given sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgo2M1RoA_cB",
    "nbpresent": {
     "id": "c020a8fb-ff61-4479-aecf-5ca4f8004ed3"
    }
   },
   "source": [
    "#### In-domain Word Embeddings (BERT)\n",
    "\n",
    "Wikipedia text is unsuitable for computer programming context. So, authors pre-trained three in-domain word embeddings on 152 million sentences from [StackOverflow 10-year archive](https://archive.org/details/stackexchange), including BERT (BERTOverflow), ELMo (ELMoVerflow), and GloVe (GloVerflow).\n",
    "The results showed that the NER model with BERT outperformed on identifying entities than the others. Thus, we chose BERT as our in-domain word embedding.\n",
    "\n",
    "The pretrained BERT is saved in `/root/Project/StackOverflowNER/pretrained_word_vectors/BERT/`\n",
    "\n",
    "<!-- BERT has 12 layers, hidden size 768, self-attention heads 12, total parameters 110M -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-EZ9-tACPKd",
    "nbpresent": {
     "id": "d3bd712f-2dbb-4ea6-a7ce-af689d35ad19"
    }
   },
   "source": [
    "#### Context-independent Code Recognition (Code Recognizer)\n",
    "\n",
    "A code recognition module is introduced to capture the probability of how likely a word can be a code token without considering any contextual information. Code Recognizer is a binary classifier. The implementation details are as follows:\n",
    "\n",
    "- Input features: unigram word and 6-gram character probabilities from two language models that are trained on the Gigaword corpus and all the code-snippets in the StackOverflow corpus.\n",
    "- Transform each ngram probability into a k-dimensional vector using Gaussian binning, which can improve the performance of neural models using numeric features.\n",
    "- Feed the vectorized features into a linear layer and concatenate the output with pretrained FastText character-level embeddings.\n",
    "- Pass the outputs through another hidden layer with sigmoid activation, and see if the output probability is greater than 0.5.\n",
    "\n",
    "The directory of Code Recognizer is `/root/Project/StackOverflowNER/code/BERT_NER/`. Since the source codes are too long, we picked out the training function to see how it was implemented and ran the training process in the server.\n",
    "\n",
    "**Parameters**\n",
    "- `LR=0.0015`: learning rate \n",
    "- `epochs=70`: epochs\n",
    "- `word_dim=300`: embedding dimension, the same as weights dimension in fastText\n",
    "- `hidden_layer_1_dim=30`: dimension of hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function of training Code Recognizer \"\"\"\n",
    "\n",
    "def train_ctc_model(train_file, test_file):\n",
    "    \n",
    "    # training and test dataset (default)\n",
    "    train_file = parameters_ctc['train_file']\n",
    "    test_file = parameters_ctc['test_file']\n",
    "    \n",
    "    # extract features from two language models trained on Gigaword and StackOverﬂow\n",
    "    features = Features(RESOURCES)\n",
    "    train_tokens, train_features, train_labels = features.get_features(train_file, True)\n",
    "    test_tokens, test_features, test_labels = features.get_features(test_file, False)\n",
    "    \n",
    "    # fastText embedding\n",
    "    vocab_size, word_to_id, id_to_word, word_to_vec = get_word_dict_pre_embeds(train_file, test_file)\n",
    "    train_ids, test_ids = get_train_test_word_id(train_file, test_file,  word_to_id)\n",
    "    \n",
    "    # transform each ngram probability into a k-dimensional vector using Gaussian binning\n",
    "    word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (vocab_size, parameters_ctc['word_dim']))\n",
    "    for word in word_to_vec:\n",
    "        word_embeds[word_to_id[word]]=word_to_vec[word]\n",
    "    \n",
    "    # concatenate the outputs with fastText embedding\n",
    "    ctc_classifier = NeuralClassifier(len(train_features[0]), max(train_labels) + 1, vocab_size, word_embeds)\n",
    "    ctc_classifier.to(device)\n",
    "    \n",
    "    # binary classifier\n",
    "    optimizer = torch.optim.Adam(ctc_classifier.parameters(), lr=parameters_ctc[\"LR\"])\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "    \n",
    "    # prepare dataset\n",
    "    train_x = Variable(torch.FloatTensor(train_features).to(device))\n",
    "    train_x_words = Variable(torch.LongTensor(train_ids).to(device))\n",
    "    train_y = Variable(torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "    test_x = Variable(torch.FloatTensor(test_features).to(device))\n",
    "    test_x_words = Variable(torch.LongTensor(test_ids).to(device))\n",
    "    test_y = Variable(torch.LongTensor(test_labels).to(device))\n",
    "\n",
    "    # training\n",
    "    for epoch in range(parameters_ctc['epochs']):\n",
    "        loss = ctc_classifier.CrossEntropy(train_features, train_x_words, train_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_scores,  train_preds = ctc_classifier(train_features, train_x_words)\n",
    "        test_scores, test_preds = ctc_classifier(test_features, test_x_words)\n",
    "        \n",
    "        eval(test_preds, test_labels, \"test\")\n",
    "\n",
    "    return ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "a3b318fb-6d9a-4f2e-b4fa-1506a27a890d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.428365932464601, 0.19701098799705508, 0.29119153594970726, 0.01899447679519639, 0.002]\n",
      "-------------------- test --------------------\n",
      "P:  54.4444  R: 18.5606  F:  27.6836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       736\n",
      "           1       0.54      0.19      0.28       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.65      0.56      0.56      1000\n",
      "weighted avg       0.71      0.74      0.69      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  89.2857  R: 9.4697  F:  17.1233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       736\n",
      "           1       0.89      0.09      0.17       264\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.82      0.55      0.51      1000\n",
      "weighted avg       0.79      0.76      0.68      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  85.7143  R: 4.5455  F:  8.6331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.86      0.05      0.09       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.80      0.52      0.47      1000\n",
      "weighted avg       0.77      0.75      0.65      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  100.0  R: 2.2727  F:  4.4444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       1.00      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.87      0.51      0.45      1000\n",
      "weighted avg       0.81      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  83.3333  R: 1.8939  F:  3.7037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.83      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.79      0.51      0.44      1000\n",
      "weighted avg       0.76      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  80.0  R: 1.5152  F:  2.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.80      0.02      0.03       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.77      0.51      0.44      1000\n",
      "weighted avg       0.75      0.74      0.63      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  85.7143  R: 2.2727  F:  4.428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.86      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.80      0.51      0.45      1000\n",
      "weighted avg       0.77      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  87.5  R: 2.6515  F:  5.1471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.88      0.03      0.05       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.81      0.51      0.45      1000\n",
      "weighted avg       0.78      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  92.3077  R: 4.5455  F:  8.6643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.92      0.05      0.09       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.83      0.52      0.47      1000\n",
      "weighted avg       0.79      0.75      0.65      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  90.0  R: 6.8182  F:  12.6761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       736\n",
      "           1       0.90      0.07      0.13       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.82      0.53      0.49      1000\n",
      "weighted avg       0.79      0.75      0.66      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  92.8571  R: 9.8485  F:  17.8082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       736\n",
      "           1       0.93      0.10      0.18       264\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.84      0.55      0.52      1000\n",
      "weighted avg       0.80      0.76      0.68      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  95.2381  R: 15.1515  F:  26.1438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       736\n",
      "           1       0.95      0.15      0.26       264\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.86      0.57      0.56      1000\n",
      "weighted avg       0.82      0.77      0.71      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  96.2963  R: 19.697  F:  32.7044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       736\n",
      "           1       0.96      0.20      0.33       264\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.87      0.60      0.60      1000\n",
      "weighted avg       0.83      0.79      0.73      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  89.8551  R: 23.4848  F:  37.2372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87       736\n",
      "           1       0.90      0.23      0.37       264\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.84      0.61      0.62      1000\n",
      "weighted avg       0.81      0.79      0.74      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  81.9149  R: 29.1667  F:  43.0168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88       736\n",
      "           1       0.82      0.29      0.43       264\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.81      0.63      0.65      1000\n",
      "weighted avg       0.80      0.80      0.76      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  80.3279  R: 37.1212  F:  50.7772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       736\n",
      "           1       0.80      0.37      0.51       264\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.67      0.70      1000\n",
      "weighted avg       0.81      0.81      0.78      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.7671  R: 43.5606  F:  56.0976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       736\n",
      "           1       0.79      0.44      0.56       264\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.81      0.70      0.72      1000\n",
      "weighted avg       0.82      0.82      0.80      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.8786  R: 50.3788  F:  60.8696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       736\n",
      "           1       0.77      0.50      0.61       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.81      0.72      0.75      1000\n",
      "weighted avg       0.82      0.83      0.82      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  73.7624  R: 56.4394  F:  63.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       736\n",
      "           1       0.74      0.56      0.64       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.80      0.75      0.76      1000\n",
      "weighted avg       0.82      0.83      0.82      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.875  R: 60.9848  F:  65.9836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       736\n",
      "           1       0.72      0.61      0.66       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.79      0.76      0.78      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.0833  R: 65.5303  F:  68.6508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       736\n",
      "           1       0.72      0.66      0.69       264\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.80      0.78      0.79      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.1569  R: 69.697  F:  70.9056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       736\n",
      "           1       0.72      0.70      0.71       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.80      0.80      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.3208  R: 71.5909  F:  71.4556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       736\n",
      "           1       0.71      0.72      0.71       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.4801  R: 75.0  F:  73.1978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       736\n",
      "           1       0.71      0.75      0.73       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.82      0.82      1000\n",
      "weighted avg       0.86      0.85      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0247  R: 76.1364  F:  73.4918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       736\n",
      "           1       0.71      0.76      0.73       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.82      0.82      1000\n",
      "weighted avg       0.86      0.85      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0345  R: 78.0303  F:  74.3682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       736\n",
      "           1       0.71      0.78      0.74       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.83      0.82      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.9898  R: 78.7879  F:  74.6858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.71      0.79      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.8475  R: 79.1667  F:  74.7764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.71      0.79      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.3333  R: 79.9242  F:  74.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.70      0.80      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.1987  R: 80.303  F:  74.9117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.70      0.80      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.84      0.83      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.7641  R: 80.6818  F:  75.3982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.83      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.5719  R: 81.0606  F:  76.0213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       736\n",
      "           1       0.72      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.2973  R: 81.0606  F:  76.4286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       736\n",
      "           1       0.72      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  72.5086  R: 79.9242  F:  76.036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       736\n",
      "           1       0.73      0.80      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.83      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  73.2639  R: 79.9242  F:  76.4493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       736\n",
      "           1       0.73      0.80      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  73.6842  R: 79.5455  F:  76.5027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.80      0.77       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.1135  R: 79.1667  F:  76.5568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.88      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.0214  R: 78.7879  F:  76.3303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.84      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.2857  R: 78.7879  F:  76.4706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  75.6364  R: 78.7879  F:  77.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  75.9124  R: 78.7879  F:  77.3234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.3838  R: 78.4091  F:  77.3832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.4925  R: 77.6515  F:  77.0677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.779  R: 77.6515  F:  77.2128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3585  R: 77.6515  F:  77.5047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.4436  R: 78.0303  F:  77.7358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.2388  R: 78.4091  F:  77.8195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.2772  R: 79.1667  F:  78.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.2772  R: 79.1667  F:  78.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.6952  R: 79.1667  F:  78.424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.78       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.85      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.022  R: 80.6818  F:  79.3296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.4194  R: 81.8182  F:  79.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.82      0.80       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.87      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.0609  R: 81.4394  F:  79.1897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.2563  R: 81.0606  F:  79.1128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3723  R: 80.303  F:  78.8104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.77      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3723  R: 80.303  F:  78.8104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.77      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.5735  R: 79.9242  F:  78.7313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.85      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.8598  R: 79.9242  F:  78.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.1481  R: 79.9242  F:  79.0262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train Code Recognizer \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/BERT_NER/')\n",
    "\n",
    "from utils_ctc import *\n",
    "from utils_ctc.prediction_ctc import *\n",
    "\n",
    "# training dataset & test dataset\n",
    "train_file = parameters_ctc['train_file']\n",
    "test_file = parameters_ctc['test_file']\n",
    "\n",
    "# train the Code Recognizer\n",
    "ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features = train_ctc_model(train_file, test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training results above, our Code Recognizer model achieves the precision of 78.44, the recall of 79.92, and the $F_1$ scores of 79.14. In the paper, the Code Recognizer model has the precision of 78.43, the recall of 83.33, and the $F_1$ scores of 80.80. Though there exist some differences, results from our training model agree well with the authors.\n",
    "\n",
    "![paperCodeRecogizer](./notebook_resources/paperCodeRecogizer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceF_grl6CSPB",
    "nbpresent": {
     "id": "fc9a1a00-1e64-4ea7-ab87-fd5c8b7ce5e9"
    }
   },
   "source": [
    "#### Entity segmentation (Entity Segmenter)\n",
    "\n",
    "The segmentation task refers to identifying entity spans without assigning entity category. The Entity Segmenter model trained on the annotated StackOverﬂow corpus can achieve 90.41% precision on the validation dataset. The Entity Segmenter concatenates with two hand-crafted features:\n",
    "\n",
    "- **Word frequency**, which represents the word occurrence count in the training set. In the given StackOverflow corpus, code and non-code have an average frequency of 1.47 and 7.41. An ambiguous token that can be either code or non-code entities, such as \"windows\", have a much higher average frequency of 92.57.\n",
    "\n",
    "- **Code markdown**, which indicates whether the given token appears inside a `⟨code⟩` markdown in the StackOverflow post. This is noisy as users do not always enclose inline code in a `⟨code⟩` tag or sometimes use the tag to highlight non-code texts.\n",
    "\n",
    "\n",
    "The segmentation model follows the simple BERT fine-tuning architecture except for the input, where BERT embeddings are concatenated with 100-dimensional code markdown and 10-dimensional word frequency features. \n",
    "\n",
    "**Noted that** some essential files (such as word frequency) and the pretrained model are missing in the folder provided by the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtuFvnA3CUzA",
    "nbpresent": {
     "id": "24e48ef2-8827-45fb-b019-2978d68d4511"
    }
   },
   "source": [
    "### Embedding-Level Attention\n",
    "\n",
    "For each word $w_i$, there are 3 embeddings \n",
    "- BERT ($w_{i1}$)\n",
    "- Code recognizer ($w_{i2}$)\n",
    "- Entity Segmenter ($w_{i3}$)\n",
    "\n",
    "The embedding-level attention $\\alpha_{it}$ ($t \\in \\{1, 2, 3\\}$) captures the word's contribution to the meaning of the word. (~params to be learned~)\n",
    "\n",
    "To compute $\\alpha_{it}$, we pass the input embeddings through a bidirectional GRU and generate their corresponding hidden representations $h_{it} = \\vec{GRU}(w_{it})$\n",
    "\n",
    "These vectors are then passed through a non-linear layer, which outputs $u_{it} = tanh(W_e h_{it} + b_e)$.\n",
    "\n",
    "$u_e$: randomly initialized and updated during the training process.\n",
    "\n",
    "This context vector is combined with the hidden embedding representation using a softmax function to extract weight of the embeddings:\n",
    "$$\n",
    "  \\alpha_{it} = \\frac{\\exp{u_{it}^T u_e}}{\\sum_t \\exp{u_{it}^T u_e}}\n",
    "$$\n",
    "\n",
    "Finally, we create the word vector by a weighted sum of all the information from different embeddings as \n",
    "$$\n",
    "  word_i = \\sum_t \\alpha_{it}h_{it}\n",
    "$$\n",
    "\n",
    "\n",
    "![embeding](./notebook_resources/embeddingLevel.png)\n",
    "\n",
    "\n",
    "The result is then fed into a linear-CRF layer, which predicts the entity category for each word based the BIO tagging schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7f513780-acb7-4087-940c-77a4eb4a9d2c"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/Attentive_BiLSTM')\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import utils_so as utils \n",
    "from utils_so import *\n",
    "\n",
    "from config_so import parameters\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(parameters[\"seed\"])\n",
    "\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "from HAN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_so import *\n",
    "\n",
    "class Embedded_Attention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Embedded_Attention, self).__init__()\n",
    "    \n",
    "    self.max_len = 3\n",
    "    self.input_dim = 1824\n",
    "    self.hidden_dim = 150\n",
    "    self.bidirectional = True\n",
    "    self.drop_out_rate = 0.5 \n",
    "    self.context_vector_size = [parameters['embedding_context_vecotr_size'], 1]\n",
    "    self.drop = nn.Dropout(p=self.drop_out_rate)\n",
    "    self.word_GRU = nn.GRU(input_size=self.input_dim, \n",
    "                           hidden_size=self.hidden_dim,\n",
    "                           bidirectional=self.bidirectional,\n",
    "                           batch_first=True)\n",
    "    self.w_proj = nn.Linear(in_features=2*self.hidden_dim ,out_features=2*self.hidden_dim)\n",
    "    self.w_context_vector = nn.Parameter(torch.randn(self.context_vector_size).float())\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    init_gru(self.word_GRU)\n",
    "\n",
    "  def forward(self,x):  \n",
    "    x, _ = self.word_GRU(x)\n",
    "    Hw = torch.tanh(self.w_proj(x))\n",
    "    w_score = self.softmax(Hw.matmul(self.w_context_vector))\n",
    "    x = x.mul(w_score)\n",
    "    x = torch.sum(x, dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current configuration\n",
    "- `LR`: learning rate\n",
    "- `epochs`: number of epochs to train\n",
    "- `lower`: lowercase all inputs\n",
    "- `zeros`: replace all digits by 0\n",
    "- `char_dim`: Character embedding dimension\n",
    "- `char_lstm_dim`: Char LSTM hidden layer size\n",
    "- `char_bidirect`: Use bidirectional LSTM for chars\n",
    "- `word_dim`: Token embedding dimension\n",
    "- `word_lstm_dim`: Token LSTM hidden layer size\n",
    "- `word_bidirect`: Use bidirectional LSTM for words\n",
    "- `dropout`: Droupout on the input\n",
    "- `char_mode`: char_CNN or char_LSTM\n",
    "- `use_elmo`: whether or not to ues elmo\n",
    "- `use_elmo_w_char`: whether or not to ues elmo with char embeds\n",
    "- `use_freq_vector`: whether or not to ues the word frequency\n",
    "- `freq_mapper_bin_count`: how many bins to use in gaussian binning of the frequency vector\n",
    "- `freq_mapper_bin_width`: the width of each bin for the gaussian binning of the frequency vector\n",
    "- `use_segmentation_vector`: whether or not to ues the code_pred vector\n",
    "- `use_han`: whether or not to ues Hierarchical Attention Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\n",
    "    'LR', 'epochs', 'lower', 'zeros', \n",
    "    'char_dim', 'char_lstm_dim', 'char_bidirect', 'word_dim', \n",
    "    'word_lstm_dim', 'word_bidirect', 'dropout', 'char_mode', \n",
    "    'use_elmo', 'use_elmo_w_char', 'use_freq_vector', 'freq_mapper_bin_count', \n",
    "    'freq_mapper_bin_width', 'use_segmentation_vector', 'use_han']:\n",
    "    print(k, parameters[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b5e3c966-5ff5-4329-92eb-7d7fe3733ab8"
    }
   },
   "source": [
    "2 special tokens `<START>` and `<STOP>` are defined to specify the starting and ending point of the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4de9720c-2f96-4811-9699-4cf837f10344"
    }
   },
   "outputs": [],
   "source": [
    "START_TAG = '<START>'\n",
    "STOP_TAG = '<STOP>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for convinence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "366f5005-d4d6-412f-be75-296720d8724c"
    }
   },
   "outputs": [],
   "source": [
    "def to_scalar(var):\n",
    "    return var.view(-1).data.tolist()[0]\n",
    "\n",
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return to_scalar(idx)\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    # vec 2D: 1 * tagset_size\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "91e04a86-aa6e-4463-ad32-59d104114ff4"
    }
   },
   "outputs": [],
   "source": [
    "def _align_word(input_matrix, word_pos_list=[1]):\n",
    "    \"\"\"\n",
    "        To change presentation of the batch.\n",
    "    Args:\n",
    "        input_matrix (autograd.Variable):  The presentation of the word in the sentence. [sentence_num, sentence_embedding]\n",
    "        word_pos_list (list): The list contains the position of the word in the current sentence.\n",
    "        \n",
    "    Returns:\n",
    "        new_matrix (torch.FloatTensor): The aligned matrix, and its each row is one sentence in the passage.\n",
    "                                        [passage_num, max_len, embedding_size]\n",
    "    \"\"\"\n",
    "    embedding_size = input_matrix.shape[-1]      # To get the embedding size of the sentence\n",
    "    number_of_words = len(word_pos_list)                  # To get the number of the sentences\n",
    "    max_len=1\n",
    "    new_matrix = autograd.Variable(torch.zeros(number_of_words, max_len, embedding_size))\n",
    "    init_index = 0\n",
    "    for index, length in enumerate(word_pos_list):\n",
    "        end_index = init_index + length\n",
    "        # temp_matrix\n",
    "        temp_matrix = input_matrix[init_index:end_index, :]      # To get one passage sentence embedding.\n",
    "        if temp_matrix.shape[0] > max_len:\n",
    "            temp_matrix = temp_matrix[:max_len]\n",
    "        new_matrix[index, -length:, :] = temp_matrix\n",
    "        # update the init_index of the input matrix\n",
    "        init_index = length\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "07b39fd9-d60b-4623-9246-e672f9cd3979"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, freq_embed_dim, \n",
    "                 seg_pred_embed_dim, hidden_dim, char_lstm_dim=25,\n",
    "                 char_to_ix=None, pre_word_embeds=None, word_freq_embeds=None, word_ner_pred_embeds=None, \n",
    "                 word_seg_pred_embeds=None, word_markdown_embeds=None, word_ctc_pred_embeds=None, char_embedding_dim=25, use_gpu=False,\n",
    "                 n_cap=None, cap_embedding_dim=None, use_crf=True, char_mode='CNN'):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.n_cap = n_cap\n",
    "        self.cap_embedding_dim = cap_embedding_dim\n",
    "        self.use_crf = use_crf\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.out_channels = char_lstm_dim\n",
    "        self.char_mode = char_mode\n",
    "        self.embed_attn = Embedded_Attention()\n",
    "        self.word_attn = Word_Attn()        \n",
    "        self.use_elmo = parameters['use_elmo']\n",
    "\n",
    "        if self.use_elmo:\n",
    "            options_file = parameters[\"elmo_options\"]\n",
    "            weight_file = parameters[\"elmo_weight\"]\n",
    "\n",
    "            self.elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "            self.elmo_2 = ElmoEmbedder(options_file, weight_file)\n",
    "        \n",
    "        print('char_mode: %s, out_channels: %d, hidden_dim: %d, ' % (char_mode, char_lstm_dim, hidden_dim))\n",
    "        if parameters['use_han']:\n",
    "            self.lstm=nn.LSTM(300, hidden_dim, bidirectional=True)\n",
    "        else:\n",
    "            self.lstm=nn.LSTM(1824, hidden_dim, bidirectional=True)\n",
    "        \n",
    "        if self.use_elmo:\n",
    "            \n",
    "            if parameters['use_elmo_w_char']:\n",
    "                if self.n_cap and self.cap_embedding_dim:\n",
    "                    self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "                    init_embedding(self.cap_embeds.weight)\n",
    "\n",
    "                if char_embedding_dim is not None:\n",
    "                    self.char_lstm_dim = char_lstm_dim\n",
    "                    self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "                    init_embedding(self.char_embeds.weight)\n",
    "\n",
    "                    if self.char_mode == 'LSTM':\n",
    "                        self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                        init_lstm(self.char_lstm)\n",
    "                    if self.char_mode == 'CNN':\n",
    "                        self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "        else:\n",
    "            if self.n_cap and self.cap_embedding_dim:\n",
    "                self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "                init_embedding(self.cap_embeds.weight)\n",
    "\n",
    "            if char_embedding_dim is not None:\n",
    "                self.char_lstm_dim = char_lstm_dim\n",
    "                self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "                init_embedding(self.char_embeds.weight)\n",
    "                \n",
    "                if self.char_mode == 'LSTM':\n",
    "                    self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                    init_lstm(self.char_lstm)\n",
    "                if self.char_mode == 'CNN':\n",
    "                    self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "\n",
    "            self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "            if pre_word_embeds is not None:\n",
    "                self.pre_word_embeds = True\n",
    "                self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "            else:\n",
    "                self.pre_word_embeds = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(parameters['dropout'])\n",
    "\n",
    "        #----------adding frequency embedding--------\n",
    "        self.freq_embeds = nn.Embedding(vocab_size, freq_embed_dim)\n",
    "        if word_freq_embeds is not None:\n",
    "            self.word_freq_embeds = True\n",
    "            self.freq_embeds.weight = nn.Parameter(torch.FloatTensor(word_freq_embeds))\n",
    "        else:\n",
    "            self.word_freq_embeds = False\n",
    "        \n",
    "        #----------adding segmentation embedding--------\n",
    "        self.seg_embeds = nn.Embedding(parameters['segmentation_count'], parameters['segmentation_dim'])\n",
    "        if word_seg_pred_embeds is not None:\n",
    "            self.use_seg_pred_embed = True\n",
    "            self.seg_embeds.weight = nn.Parameter(torch.FloatTensor(word_seg_pred_embeds))\n",
    "        else:\n",
    "            self.use_seg_pred_embed = False\n",
    "        \n",
    "        #----------adding ctc prediction embedding--------\n",
    "        self.ctc_pred_embeds = nn.Embedding(parameters['code_recognizer_count'], parameters['code_recognizer_dim'])\n",
    "        if word_ctc_pred_embeds is not None:\n",
    "            self.use_ctc_pred_embed = True\n",
    "            self.ctc_pred_embeds.weight = nn.Parameter(torch.FloatTensor(word_ctc_pred_embeds))\n",
    "        else:\n",
    "            self.use_ctc_pred_embed = False\n",
    "        \n",
    "        init_lstm(self.lstm)\n",
    "        # init_lstm(self.lstm_2)\n",
    "        self.hw_trans = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.hw_gate = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.h2_h1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
    "        init_linear(self.h2_h1)\n",
    "        init_linear(self.hidden2tag)\n",
    "        init_linear(self.hw_gate)\n",
    "        init_linear(self.hw_trans)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.transitions = nn.Parameter(\n",
    "                torch.zeros(self.tagset_size, self.tagset_size))\n",
    "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # tags is ground_truth, a list of ints, length is len(sentence)\n",
    "        # feats is a 2D tensor, len(sentence) * tagset_size\n",
    "        r = torch.LongTensor(range(feats.size()[0]))\n",
    "        if self.use_gpu:\n",
    "            r = r.cuda()\n",
    "            pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
    "            pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
    "        else:\n",
    "            pad_start_tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
    "            pad_stop_tags = torch.cat([tags, torch.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
    "\n",
    "        score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(feats[r, tags])\n",
    "\n",
    "        return score    \n",
    "\n",
    "    def get_char_embedding(self, sentence, chars2, caps, chars2_length, d):\n",
    "        if self.char_mode == 'LSTM':\n",
    "            chars_embeds = self.char_embeds(chars2).transpose(0, 1)\n",
    "            packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)\n",
    "            lstm_out, _ = self.char_lstm(packed)\n",
    "            outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "            outputs = outputs.transpose(0, 1)\n",
    "            chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n",
    "            if self.use_gpu:\n",
    "                chars_embeds_temp = chars_embeds_temp.cuda()\n",
    "            for i, index in enumerate(output_lengths):\n",
    "                chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
    "            chars_embeds = chars_embeds_temp.clone()\n",
    "            for i in range(chars_embeds.size(0)):\n",
    "                chars_embeds[d[i]] = chars_embeds_temp[i]\n",
    "\n",
    "        if self.char_mode == 'CNN':\n",
    "            chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
    "            chars_cnn_out3 = nn.functional.relu(self.char_cnn3(chars_embeds))   \n",
    "            chars_embeds = nn.functional.max_pool2d(\n",
    "                chars_cnn_out3,\n",
    "                kernel_size=(chars_cnn_out3.size(2), 1)\n",
    "            ).view(chars_cnn_out3.size(0), self.out_channels)\n",
    "        return chars_embeds\n",
    "\n",
    "    def _get_lstm_features_w_elmo_and_char(self, sentence_words, sentence,markdown, chars2, caps, chars2_length, d):\n",
    "        if self.char_mode == 'LSTM':\n",
    "            # self.char_lstm_hidden = self.init_lstm_hidden(dim=self.char_lstm_dim, bidirection=True, batchsize=chars2.size(0))\n",
    "            chars_embeds = self.char_embeds(chars2).transpose(0, 1)\n",
    "            packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)\n",
    "            lstm_out, _ = self.char_lstm(packed)\n",
    "            outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "            outputs = outputs.transpose(0, 1)\n",
    "            chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n",
    "            if self.use_gpu:\n",
    "                chars_embeds_temp = chars_embeds_temp.cuda()\n",
    "            for i, index in enumerate(output_lengths):\n",
    "                chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
    "            chars_embeds = chars_embeds_temp.clone()\n",
    "            for i in range(chars_embeds.size(0)):\n",
    "                chars_embeds[d[i]] = chars_embeds_temp[i]\n",
    "\n",
    "        if self.char_mode == 'CNN':\n",
    "            chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
    "            # chars_cnn_out3 = self.char_cnn3(chars_embeds)\n",
    "            chars_cnn_out3 = nn.functional.relu(self.char_cnn3(chars_embeds))   \n",
    "            chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,\n",
    "                                                 kernel_size=(chars_cnn_out3.size(2), 1)).view(chars_cnn_out3.size(0), self.out_channels)\n",
    "        \n",
    "        character_ids = batch_to_ids([sentence_words])\n",
    "        if self.use_gpu:\n",
    "            character_ids = character_ids.cuda()\n",
    "        embeddings = self.elmo(character_ids)\n",
    "        embeddings = embeddings['elmo_representations'][0]\n",
    "        embeds = embeddings[0]\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            embeds=embeds.cuda()\n",
    "        \n",
    "        embeds = torch.cat((embeds, chars_embeds), 1)\n",
    "        embeds = embeds.unsqueeze(1)\n",
    "        # print(embeds.size())\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = lstm_out.view(len(sentence_words), self.hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def apply_attention(self, elmo_embeds, seg_embeds, ctc_embeds):\n",
    "        word_tensor_list = []\n",
    "        word_pos_list=[]\n",
    "        sent_len =elmo_embeds.size()[0]\n",
    "\n",
    "        for index in range(sent_len):\n",
    "            elmo_rep = elmo_embeds[index]\n",
    "            ctc_rep = ctc_embeds[index]\n",
    "            seg_rep = seg_embeds[index]\n",
    "            comb_rep = torch.cat((elmo_rep, ctc_rep, seg_rep)).view(1, 1, -1)\n",
    "            attentive_rep=self.embed_attn(comb_rep)\n",
    "            word_tensor_list.append(attentive_rep)\n",
    "            word_pos_list.append(index+1)\n",
    "\n",
    "        word_tensor =  torch.stack(word_tensor_list)\n",
    "        if self.use_gpu:\n",
    "            word_tensor=word_tensor.cuda()\n",
    "        \n",
    "        x = _align_word(word_tensor, word_pos_list)\n",
    "        if self.use_gpu:\n",
    "            x=x.cuda()\n",
    "        y = self.word_attn(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "    def _get_lstm_features_w_elmo(self, sentence_words, sentence, seg_pred, ctc_pred):\n",
    "        character_ids = batch_to_ids([sentence_words])\n",
    "        if self.use_gpu:\n",
    "            character_ids = character_ids.cuda()\n",
    "        embeddings = self.elmo(character_ids)\n",
    "        embeddings = embeddings['elmo_representations'][0]\n",
    "        embeds = embeddings[0]\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            embeds=embeds.cuda()\n",
    "            elmo_embeds=embeds.cuda()\n",
    "        else:\n",
    "            elmo_embeds=embeds\n",
    "\n",
    "        if parameters['use_freq_vector']:\n",
    "            frequency_embeddings = self.freq_embeds(sentence)\n",
    "            embeds = torch.cat((embeds, frequency_embeddings), 0)\n",
    "        \n",
    "        if parameters['use_segmentation_vector'] :\n",
    "            segment_embeddings = self.seg_embeds(seg_pred)\n",
    "            embeds = torch.cat((embeds, segment_embeddings), 1)\n",
    "        \n",
    "        if parameters['use_code_recognizer_vector']:\n",
    "            ctc_pred_embeddings = self.ctc_pred_embeds(ctc_pred)\n",
    "            embeds = torch.cat((embeds, ctc_pred_embeddings), 1)\n",
    "        \n",
    "        if parameters['use_han']:\n",
    "            attentive_word_embeds = self.apply_attention(elmo_embeds, segment_embeddings, ctc_pred_embeddings)\n",
    "            embeds=attentive_word_embeds\n",
    "        else:\n",
    "            embeds = embeds.unsqueeze(1)\n",
    "        \n",
    "        embeds = self.dropout(embeds)\n",
    "        \n",
    "\n",
    "        # embeds = self.dropout(merged_embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        #lstm_out, _ = self.lstm_2(lstm_out)\n",
    "        lstm_out = lstm_out.view(len(sentence_words), self.hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "    \n",
    "    def _get_lstm_features(self, sentence, markdown, chars2, caps, chars2_length, d):\n",
    "\n",
    "        if self.char_mode == 'LSTM':\n",
    "            # self.char_lstm_hidden = self.init_lstm_hidden(dim=self.char_lstm_dim, bidirection=True, batchsize=chars2.size(0))\n",
    "            chars_embeds = self.char_embeds(chars2).transpose(0, 1)\n",
    "            packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)\n",
    "            lstm_out, _ = self.char_lstm(packed)\n",
    "            outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "            outputs = outputs.transpose(0, 1)\n",
    "            chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n",
    "            if self.use_gpu:\n",
    "                chars_embeds_temp = chars_embeds_temp.cuda()\n",
    "            for i, index in enumerate(output_lengths):\n",
    "                chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
    "            chars_embeds = chars_embeds_temp.clone()\n",
    "            for i in range(chars_embeds.size(0)):\n",
    "                chars_embeds[d[i]] = chars_embeds_temp[i]\n",
    "\n",
    "        if self.char_mode == 'CNN':\n",
    "            chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
    "            # chars_cnn_out3 = self.char_cnn3(chars_embeds)\n",
    "            chars_cnn_out3 = nn.functional.relu(self.char_cnn3(chars_embeds))   \n",
    "            chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,\n",
    "                                                 kernel_size=(chars_cnn_out3.size(2), 1)).view(chars_cnn_out3.size(0), self.out_channels)\n",
    "\n",
    "        # t = self.hw_gate(chars_embeds)\n",
    "        # g = nn.functional.sigmoid(t)\n",
    "        # h = nn.functional.relu(self.hw_trans(chars_embeds))\n",
    "        # chars_embeds = g * h + (1 - g) * chars_embeds\n",
    "\n",
    "        embeds = self.word_embeds(sentence)\n",
    "        \n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            cap_embedding = self.cap_embeds(caps)\n",
    "\n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            embeds = torch.cat((embeds, chars_embeds, cap_embedding), 1)\n",
    "        else:\n",
    "            embeds = torch.cat((embeds, chars_embeds), 1)\n",
    "\n",
    "        if parameters['use_freq_vector']:\n",
    "            frequency_embeddings = self.freq_embeds(sentence)\n",
    "            embeds = torch.cat((embeds, frequency_embeddings), 1)\n",
    "        if parameters['use_markdown_vector'] :\n",
    "            markdown_embeddings = self.markdown_embeds(markdown)\n",
    "            embeds = torch.cat((embeds, markdown_embeddings), 1)\n",
    "        \n",
    "        embeds = embeds.unsqueeze(1) #what is done here\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # calculate in log domain\n",
    "        # feats is len(sentence) * tagset_size\n",
    "        # initialize alpha with a Tensor with values all equal to -10000.\n",
    "        init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "        forward_var = autograd.Variable(init_alphas)\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            emit_score = feat.view(-1, 1)\n",
    "            tag_var = forward_var + self.transitions + emit_score\n",
    "            max_tag_var, _ = torch.max(tag_var, dim=1)\n",
    "            tag_var = tag_var - max_tag_var.view(-1, 1)\n",
    "            forward_var = max_tag_var + torch.log(torch.sum(torch.exp(tag_var), dim=1)).view(1, -1) # ).view(1, -1)\n",
    "        terminal_var = (forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        # Z(x)\n",
    "        return alpha\n",
    "\n",
    "    def viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        # analogous to forward\n",
    "        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0.0\n",
    "        forward_var = Variable(init_vvars)\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
    "            _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
    "            bptrs_t = bptrs_t.squeeze().data.cpu().numpy()\n",
    "            next_tag_var = next_tag_var.data.cpu().numpy()\n",
    "            viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t]\n",
    "            viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
    "            if self.use_gpu:\n",
    "                viterbivars_t = viterbivars_t.cuda()\n",
    "            forward_var = viterbivars_t + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
    "        terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
    "        best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
    "        path_score = terminal_var[best_tag_id]\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence_tokens, sentence, sentence_seg_preds,sentence_ctc_preds, tags, chars2, caps, chars2_length, d):\n",
    "        # sentence, tags is a list of ints\n",
    "        # features is a 2D tensor, len(sentence) * self.tagset_size\n",
    "        feats = self._get_lstm_features_w_elmo(sentence_tokens, sentence, sentence_seg_preds, sentence_ctc_preds)\n",
    "\n",
    "#         if self.use_elmo:\n",
    "#             if parameters['use_elmo_w_char']:\n",
    "#                 feats = self._get_lstm_features_w_elmo_and_char(sentence_tokens, sentence, sentence_markdowns, chars2, caps, chars2_length, d)\n",
    "#             else:\n",
    "#                 feats = self._get_lstm_features_w_elmo(sentence_tokens, sentence, sentence_seg_preds, sentence_ctc_preds)\n",
    "#         else:\n",
    "#             feats = self._get_lstm_features(sentence,sentence_markdowns, chars2, caps, chars2_length, d)\n",
    "\n",
    "        if self.use_crf:\n",
    "            forward_score = self._forward_alg(feats)\n",
    "            gold_score = self._score_sentence(feats, tags)\n",
    "            return forward_score - gold_score\n",
    "        else:\n",
    "            tags = Variable(tags)\n",
    "            scores = nn.functional.cross_entropy(feats, tags)\n",
    "            return scores\n",
    "\n",
    "\n",
    "    def forward(self,sentence_tokens, sentence, sentence_seg_preds, sentence_ctc_preds, chars, caps, chars2_length, d):\n",
    "        feats = self._get_lstm_features_w_elmo(sentence_tokens,  sentence, sentence_seg_preds,sentence_ctc_preds)\n",
    "\n",
    "        # if self.use_elmo:\n",
    "        #     if parameters['use_elmo_w_char']:\n",
    "        #         feats = self._get_lstm_features_w_elmo_and_char(sentence_tokens, sentence,sentence_markdowns, chars, caps, chars2_length, d)\n",
    "        #     else:\n",
    "        #         feats = self._get_lstm_features_w_elmo(sentence_tokens,  sentence, sentence_markdowns,sentence_ctc_preds)\n",
    "            \n",
    "        # else:\n",
    "        #     feats = self._get_lstm_features(sentence,sentence_markdowns, chars, caps, chars2_length, d)\n",
    "        # viterbi to get tag_seq\n",
    "        if self.use_crf:\n",
    "            score, tag_seq = self.viterbi_decode(feats)\n",
    "        else:\n",
    "            score, tag_seq = torch.max(feats, 1)\n",
    "            tag_seq = list(tag_seq.cpu().data)\n",
    "\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ed8566a0-56a4-48d5-8e9b-8d3aba6970ce"
    }
   },
   "source": [
    "### Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "79315216-006f-4cd9-9670-6e917a158752"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_train_set_dev_data():\n",
    "    lower = parameters['lower']\n",
    "    zeros = parameters['zeros']\n",
    "    tag_scheme = parameters['tag_scheme']\n",
    "    \n",
    "    # create the frequency vector\n",
    "    if parameters['use_freq_vector']:\n",
    "        create_frequecny_vector()\n",
    "    \n",
    "    # create the ctc_dict\n",
    "    ctc_pred_dict = {}\n",
    "    for line in open(parameters[\"ctc_pred\"]):\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        line_values = line.strip().split(\"\\t\")\n",
    "        word, ctc_pred = line_values[0], line_values[-1]\n",
    "        ctc_pred_dict[word] = ctc_pred\n",
    "    print(\"completed ctc predictions reading \")\n",
    "\n",
    "    # prepare the training data\n",
    "    # merge labels and select category specific entities \n",
    "    input_train_file=utils.Merge_Label(parameters[\"train\"])\n",
    "    \n",
    "    Sort_Entity_by_Count(input_train_file,parameters[\"sorted_entity_list_file_name\"])\n",
    "\n",
    "    with open(parameters[\"sorted_entity_list_file_name\"], encoding='utf-8') as f:\n",
    "        sorted_entity_list = json.load(f)\n",
    "    set_of_selected_tags=[]\n",
    "\n",
    "    entity_category_code=parameters[\"entity_category_code\"]\n",
    "    entity_category_human_language=parameters[\"entity_category_human_language\"]\n",
    "\n",
    "    set_of_selected_tags.extend(sorted_entity_list[0:-6])\n",
    "    if parameters['entity_category'] == 'code':\n",
    "        for entity in entity_category_human_language:\n",
    "            if entity in entity_category_human_language and entity in set_of_selected_tags:\n",
    "                set_of_selected_tags.remove(entity)\n",
    "    \n",
    "    if parameters['entity_category'] == 'human_lang':\n",
    "        for entity in entity_category_code:\n",
    "            if entity in entity_category_code and entity in set_of_selected_tags:\n",
    "                set_of_selected_tags.remove(entity)\n",
    "        if 'Algorithm' not in set_of_selected_tags:\n",
    "            set_of_selected_tags.append('Algorithm')\n",
    "    \n",
    "    if parameters['entity_category'] == 'all':\n",
    "        if 'Algorithm' not in set_of_selected_tags:\n",
    "            set_of_selected_tags.append('Algorithm')\n",
    "    \n",
    "    print(\"set of entities: \", set_of_selected_tags)\n",
    "\n",
    "    merge_tags=parameters['merge_tags']\n",
    "    train_sentences = loader.load_sentences_so_w_pred(parameters[\"train\"], parameters[\"train_pred\"], lower, zeros, merge_tags, set_of_selected_tags)\n",
    "    if parameters[\"mode\"] == \"dev\":\n",
    "        dev_sentences = loader.load_sentences_so_w_pred(parameters[\"dev\"], parameters[\"dev_pred\"], lower, zeros, merge_tags, set_of_selected_tags)\n",
    "        test_sentences = dev_sentences\n",
    "    elif parameters[\"mode\"] == \"test\":\n",
    "        dev_sentences = loader.load_sentences_so_w_pred(parameters[\"test\"], parameters[\"test_pred\"],lower, zeros, merge_tags, set_of_selected_tags)\n",
    "        test_sentences = dev_sentences\n",
    "    \n",
    "    loader.update_tag_scheme(train_sentences, tag_scheme)\n",
    "    loader.update_tag_scheme(dev_sentences, tag_scheme)\n",
    "    loader.update_tag_scheme(test_sentences, tag_scheme)\n",
    "    \n",
    "    dico_words_train = loader.word_mapping(train_sentences, lower)[0]\n",
    "    dico_chars, char_to_id, id_to_char = loader.char_mapping(train_sentences)\n",
    "    dico_tags, tag_to_id, id_to_tag = loader.tag_mapping(train_sentences)    \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    #------------- based on parameters setting(should be set by command line argutments) ------------------------\n",
    "    #------------- load pretrained word embeddings --------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    if parameters['all_emb']:\n",
    "        all_dev_test_words=[w[0][0] for w in dev_sentences+test_sentences]\n",
    "    else:\n",
    "        all_dev_test_words = []\n",
    "\n",
    "    if parameters['use_pre_emb']:\n",
    "        dico_words, word_to_id, id_to_word = loader.augment_with_pretrained(\n",
    "            dico_words_train.copy(),\n",
    "            parameters['pre_emb'],\n",
    "            all_dev_test_words\n",
    "        )\n",
    "    else:\n",
    "        dico_words = dico_words_train\n",
    "        word_to_id, id_to_word = loader.create_mapping(dico_words_train.copy())\n",
    "\n",
    "    train_data = loader.prepare_dataset(train_sentences, word_to_id, char_to_id, tag_to_id, ctc_pred_dict, lower)\n",
    "    dev_data = loader.prepare_dataset(dev_sentences, word_to_id, char_to_id, tag_to_id, ctc_pred_dict, lower)\n",
    "    test_data = loader.prepare_dataset(test_sentences, word_to_id, char_to_id, tag_to_id,ctc_pred_dict, lower)\n",
    "\n",
    "    all_freq_embed={}\n",
    "    for line in open(parameters['freq_vector_file'], encoding='utf-8'):\n",
    "        s = line.strip().split()\n",
    "        if len(s) == parameters['freq_dim'] + 1:\n",
    "            all_freq_embed[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "        else:\n",
    "            print(\"freq dim mismatch: \",\"required: \", parameters['freq_dim'], \"given: \",len(s)-1)\n",
    "    \n",
    "    freq_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(word_to_id), parameters['freq_dim']))\n",
    "    for w in word_to_id:\n",
    "        if w in all_freq_embed:\n",
    "            freq_embeds[word_to_id[w]] = all_freq_embed[w]\n",
    "        elif w.lower() in all_freq_embed:\n",
    "            freq_embeds[word_to_id[w]] = all_freq_embed[w.lower()]\n",
    "    \n",
    "    all_word_embeds = {}\n",
    "    if parameters['use_pre_emb']:\n",
    "        for i, line in enumerate(codecs.open(parameters['pre_emb'] , 'r', 'utf-8')):\n",
    "            s = line.strip().split()\n",
    "            if len(s) == parameters['word_dim'] + 1:\n",
    "                all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "    \n",
    "    word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(word_to_id), parameters['word_dim']))\n",
    "    seg_pred_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (parameters['segmentation_count'] , parameters['segmentation_dim']))\n",
    "    ctc_pred_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (parameters['code_recognizer_count'], parameters['code_recognizer_dim']))\n",
    "    if parameters['use_pre_emb']:\n",
    "        for w in word_to_id:\n",
    "            if w in all_word_embeds:\n",
    "                word_embeds[word_to_id[w]] = all_word_embeds[w]\n",
    "            elif w.lower() in all_word_embeds:\n",
    "                word_embeds[word_to_id[w]] = all_word_embeds[w.lower()]\n",
    "    \n",
    "    return train_data, dev_data, test_data, word_to_id, id_to_word, tag_to_id, id_to_tag, char_to_id, id_to_char, word_embeds, freq_embeds, seg_pred_embeds, ctc_pred_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fbf04ebb-f91f-41dd-9935-bb157c19435c"
    }
   },
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data, word_to_id, id_to_word, tag_to_id, id_to_tag, char_to_id, id_to_char, word_embeds, freq_embeds, seg_pred_embeds, ctc_pred_embeds = prepare_train_set_dev_data()\n",
    "model = BiLSTM_CRF(\n",
    "    vocab_size=len(word_to_id),\n",
    "    tag_to_ix=tag_to_id,\n",
    "    embedding_dim=parameters['word_dim'],\n",
    "    freq_embed_dim=parameters['freq_dim'], \n",
    "    seg_pred_embed_dim=parameters['segmentation_dim'],\n",
    "    hidden_dim=parameters['word_lstm_dim'],\n",
    "    use_gpu=parameters['use_gpu'],\n",
    "    char_to_ix=char_to_id,\n",
    "    pre_word_embeds=word_embeds,\n",
    "    word_freq_embeds=freq_embeds,\n",
    "    word_seg_pred_embeds=seg_pred_embeds,\n",
    "    word_ctc_pred_embeds=ctc_pred_embeds,\n",
    "    use_crf=parameters['crf'],\n",
    "    char_mode=parameters['char_mode'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1a350023-ed0f-4452-8d87-04c175973210"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "if parameters['use_gpu']:\n",
    "    print(\"GPU ID = \", parameters[\"gpu_id\"])\n",
    "    torch.cuda.set_device(parameters[\"gpu_id\"])\n",
    "    model.cuda()\n",
    "learning_rate = parameters[\"LR\"]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "t = time.time()\n",
    "\n",
    "# train model\n",
    "char_embed_dict = {}\n",
    "losses = []\n",
    "loss = 0.0\n",
    "best_dev_F = -1.0\n",
    "best_test_F = -1.0\n",
    "best_train_F = -1.0\n",
    "all_F = [[0, 0, 0]]\n",
    "plot_every = 10\n",
    "eval_every = 20\n",
    "count = 0\n",
    "\n",
    "model.train(True)\n",
    "start = time.time()\n",
    "# what the data instance looks like\"\n",
    "#'str_words': ['Trial', 'and', 'error', 'seems', 'a', 'very', 'dumb', '(', 'and', 'annoying', ')', 'approach', 'to', 'solve', 'this', 'problem', '.'], \n",
    "#'words':    [1, 9, 76, 179, 7, 215, 1, 26, 9, 1, 29, 332, 4, 310, 15, 64, 3], \n",
    "#'markdown': [0, 0, 0, 0, 0, 0, 0,  0, 0, 0,  0, 0, 0, 0,  0,  0, 0],\n",
    "#'chars': [[26, 8, 5, 4, 10], [4, 6, 11], [1, 8, 8, 3, 8], [7, 1, 1, 14, 7], [4], [22, 1, 8, 17], [11, 13, 14, 21], [35], [4, 6, 11], [4, 6, 6, 3, 17, 5, 6, 16], [34], [4, 15, 15, 8, 3, 4, 12, 9], [2, 3], [7, 3, 10, 22, 1], [2, 9, 5, 7], [15, 8, 3, 21, 10, 1, 14], [20]], \n",
    "#'caps': [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "#'tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'handcrafted': [28052, 28053, 28054, 28055, 28056, 28057, 28058, 28059, 28060, 28061, 28062, 28063, 28064, 28065, 28066, 28067, 28068]\n",
    "for epoch in range(1, parameters[\"epochs\"] + 1):\n",
    "    print(\"---------epoch count: \", epoch)\n",
    "    for i, index in enumerate(np.random.permutation(len(train_data))):\n",
    "\n",
    "        tr = time.time()\n",
    "        count += 1\n",
    "        data = train_data[index]\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        sentence_in = data['words']\n",
    "        sentence_tokens=data['str_words']\n",
    "        sentence_seg_preds = data['seg_pred']\n",
    "        sentence_ctc_preds = data['ctc_pred']\n",
    "        \n",
    "        tags = data['tags']\n",
    "        chars2 = data['chars']\n",
    "\n",
    "        sentence_in = Variable(torch.LongTensor(sentence_in))\n",
    "        sentence_seg_preds = Variable(torch.LongTensor(sentence_seg_preds))\n",
    "        sentence_ctc_preds = Variable(torch.LongTensor(sentence_ctc_preds))\n",
    "\n",
    "        ######### char lstm\n",
    "        if parameters['char_mode'] == 'LSTM':\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            d = {}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in d and not i in d.values():\n",
    "                        d[j] = i\n",
    "                        continue\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        \n",
    "        # ######## char cnn\n",
    "        if parameters['char_mode'] == 'CNN':\n",
    "            d = {}\n",
    "            chars2_length = [len(c) for c in chars2]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "        \n",
    "        targets = torch.LongTensor(tags)\n",
    "        caps = Variable(torch.LongTensor(data['caps']))\n",
    "        if use_gpu:\n",
    "            neg_log_likelihood = model.neg_log_likelihood(sentence_tokens, sentence_in.cuda(), sentence_seg_preds.cuda(),sentence_ctc_preds.cuda(),  targets.cuda(), chars2_mask.cuda(), caps.cuda(), chars2_length, d)\n",
    "        else:\n",
    "            neg_log_likelihood = model.neg_log_likelihood(sentence_tokens,sentence_in,sentence_seg_preds,sentence_ctc_preds,  targets, chars2_mask, caps, chars2_length, d)\n",
    "        \n",
    "        loss += neg_log_likelihood.data.item() / len(data['words']) #JT : data[0]> data.item()\n",
    "        neg_log_likelihood.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0) #JT : clip_grad_norm > clip_grad_norm_\n",
    "        optimizer.step()\n",
    "        if count % len(train_data) == 0:\n",
    "            utils.adjust_learning_rate(optimizer, lr=learning_rate/(1+0.05*count/len(train_data)))\n",
    "        \n",
    "    # JT: evaluate after 1 epoch\n",
    "    model.train(False)\n",
    "\n",
    "    best_train_F, new_train_F, _ = evaluating(model, train_data,  best_train_F,  epoch, \"train\")\n",
    "\n",
    "    if parameters[\"mode\"]==\"dev\":\n",
    "        phase_name=\"dev\"\n",
    "    else:\n",
    "        phase_name=\"test\"\n",
    "\n",
    "    best_dev_F, new_dev_F, save = evaluating(model, dev_data, best_dev_F, epoch, phase_name) \n",
    "    if save:\n",
    "        torch.save(model, model_name)\n",
    "    best_test_F, new_test_F = 0, 0\n",
    "    all_F.append([new_train_F, new_dev_F, new_test_F])\n",
    "    step_lr_scheduler.step()\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    #--------------------- save model for each epoch, after finding the optimal epoch ----------------\n",
    "    #--------------------- save model from last epoch only -------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    PATH=parameters[\"models_path\"]+\"/model_epoch.\"+str(epoch)\n",
    "    torch.save(model, PATH)\n",
    "    model.train(True)\n",
    "    end = time.time()\n",
    "    time_in_this_epoch = end - start\n",
    "    print(\"time in this epoch: \", time_in_this_epoch, \"secs\")\n",
    "    start=end\n",
    "\n",
    "print(\"total time elapsed for training: \", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Although the Entity Segmenter module is missing as mentioned above, the authors have pre-handled the dataset and provided the predictions from the Code Recognizer and the Entity Segmenter in the source codes. The details as below.\n",
    "\n",
    "![dataset](./notebook_resources/dataset.png)\n",
    "\n",
    "Thus, we can still train the SoftNER model with those datasets. 100 epochs are required for training and each epoch costs more than 4 hours on our server. We have trained 3 epochs to observe the results.\n",
    "\n",
    "The training log and the conscise results in each epoch are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: ignoring input\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "completed ctc predictions reading \r\n",
      "set of entities:  ['Class', 'Application', 'Variable', 'User_Interface_Element', 'Code_Block', 'Function', 'Language', 'Library', 'Value', 'Data_Structure', 'Data_Type', 'File_Type', 'File_Name', 'Version', 'HTML_XML_Tag', 'Device', 'Operating_System', 'Website', 'Algorithm']\r\n",
      "------------------------------------------------------------\r\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\r\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\r\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\r\n",
      "Number of sentences after merging :  9263\r\n",
      "Max len sentences has 92 words\r\n",
      "------------------------------------------------------------\r\n",
      "------------------------------------------------------------\r\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  249\r\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  315\r\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  3108\r\n",
      "Number of sentences after merging :  3108\r\n",
      "Max len sentences has 83 words\r\n",
      "------------------------------------------------------------\r\n",
      "Found 3294 unique words (136996 in total)\r\n",
      "Found 108 unique characters\r\n",
      "Found 41 unique named entity tags\r\n",
      "char_mode: CNN, out_channels: 25, hidden_dim: 300, \r\n",
      "---------epoch count:  1\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11118 phrases; correct: 8416.\r\n",
      "accuracy:  97.66%; precision:  75.70%; recall:  75.14%; FB1:  75.42\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  0\r\n",
      "      Application: precision:  83.91%; recall:  80.35%; FB1:  82.09 foundGuessed:  1243\r\n",
      "            Class: precision:  71.78%; recall:  78.51%; FB1:  74.99 foundGuessed:  1481\r\n",
      "       Code_Block: precision:  72.17%; recall:  60.00%; FB1:  65.53 foundGuessed:  690\r\n",
      "   Data_Structure: precision:  77.19%; recall:  88.66%; FB1:  82.53 foundGuessed:  719\r\n",
      "        Data_Type: precision:  79.50%; recall:  84.45%; FB1:  81.90 foundGuessed:  444\r\n",
      "           Device: precision:  59.31%; recall:  43.22%; FB1:  50.00 foundGuessed:  145\r\n",
      "        File_Name: precision:  75.78%; recall:  82.87%; FB1:  79.17 foundGuessed:  351\r\n",
      "        File_Type: precision:  98.70%; recall:  41.42%; FB1:  58.35 foundGuessed:  154\r\n",
      "         Function: precision:  79.84%; recall:  77.08%; FB1:  78.44 foundGuessed:  754\r\n",
      "     HTML_XML_Tag: precision:  83.61%; recall:  49.51%; FB1:  62.20 foundGuessed:  122\r\n",
      "         Language: precision:  77.53%; recall:  94.70%; FB1:  85.26 foundGuessed:  899\r\n",
      "          Library: precision:  69.68%; recall:  73.37%; FB1:  71.48 foundGuessed:  775\r\n",
      " Operating_System: precision:  85.07%; recall:  33.33%; FB1:  47.90 foundGuessed:  67\r\n",
      "User_Interface_Element: precision:  84.86%; recall:  81.76%; FB1:  83.28 foundGuessed:  898\r\n",
      "            Value: precision:  88.99%; recall:  68.14%; FB1:  77.18 foundGuessed:  536\r\n",
      "         Variable: precision:  62.60%; recall:  80.46%; FB1:  70.41 foundGuessed:  1441\r\n",
      "          Version: precision:  94.30%; recall:  70.82%; FB1:  80.89 foundGuessed:  193\r\n",
      "          Website: precision:  38.35%; recall:  74.53%; FB1:  50.64 foundGuessed:  206\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3838 phrases; correct: 2709.\r\n",
      "accuracy:  97.14%; precision:  70.58%; recall:  70.22%; FB1:  70.40\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  0\r\n",
      "      Application: precision:  73.62%; recall:  75.43%; FB1:  74.51 foundGuessed:  417\r\n",
      "            Class: precision:  67.24%; recall:  76.47%; FB1:  71.56 foundGuessed:  580\r\n",
      "       Code_Block: precision:  67.43%; recall:  58.28%; FB1:  62.52 foundGuessed:  261\r\n",
      "   Data_Structure: precision:  84.41%; recall:  89.88%; FB1:  87.06 foundGuessed:  263\r\n",
      "        Data_Type: precision:  84.21%; recall:  86.49%; FB1:  85.33 foundGuessed:  114\r\n",
      "           Device: precision:  51.43%; recall:  33.96%; FB1:  40.91 foundGuessed:  35\r\n",
      "        File_Name: precision:  80.77%; recall:  77.30%; FB1:  79.00 foundGuessed:  156\r\n",
      "        File_Type: precision:  93.33%; recall:  32.56%; FB1:  48.28 foundGuessed:  45\r\n",
      "         Function: precision:  72.57%; recall:  61.65%; FB1:  66.67 foundGuessed:  226\r\n",
      "     HTML_XML_Tag: precision:  61.29%; recall:  36.54%; FB1:  45.78 foundGuessed:  31\r\n",
      "         Language: precision:  69.55%; recall:  85.96%; FB1:  76.88 foundGuessed:  220\r\n",
      "          Library: precision:  65.66%; recall:  67.70%; FB1:  66.67 foundGuessed:  265\r\n",
      " Operating_System: precision:  91.18%; recall:  46.97%; FB1:  62.00 foundGuessed:  34\r\n",
      "User_Interface_Element: precision:  77.05%; recall:  79.44%; FB1:  78.22 foundGuessed:  366\r\n",
      "            Value: precision:  87.26%; recall:  62.84%; FB1:  73.07 foundGuessed:  157\r\n",
      "         Variable: precision:  53.92%; recall:  72.75%; FB1:  61.94 foundGuessed:  510\r\n",
      "          Version: precision:  87.50%; recall:  69.37%; FB1:  77.39 foundGuessed:  88\r\n",
      "          Website: precision:  28.57%; recall:  51.28%; FB1:  36.70 foundGuessed:  70\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\\begin{table}[htbp]\r\n",
      "\\centering\r\n",
      "\\begin{tabular}{|c|c|c|c|}\r\n",
      "\\hline\r\n",
      " & Precision & Recall & F1\\\\\r\n",
      "\\hline\r\n",
      "Class & 67.24 & 76.47 & 71.56\\\\\r\n",
      "Application & 73.62 & 75.43 & 74.51\\\\\r\n",
      "Variable & 53.92 & 72.75 & 61.94\\\\\r\n",
      "User Interface Element & 77.05 & 79.44 & 78.22\\\\\r\n",
      "Code Block & 67.43 & 58.28 & 62.52\\\\\r\n",
      "Function & 72.57 & 61.65 & 66.67\\\\\r\n",
      "Language & 69.55 & 85.96 & 76.88\\\\\r\n",
      "Library & 65.66 & 67.7 & 66.67\\\\\r\n",
      "Value & 87.26 & 62.84 & 73.07\\\\\r\n",
      "Data Structure & 84.41 & 89.88 & 87.06\\\\\r\n",
      "Data Type & 84.21 & 86.49 & 85.33\\\\\r\n",
      "File Type & 93.33 & 32.56 & 48.28\\\\\r\n",
      "File Name & 80.77 & 77.3 & 79.0\\\\\r\n",
      "Version & 87.5 & 69.37 & 77.39\\\\\r\n",
      "HTML XML Tag & 61.29 & 36.54 & 45.78\\\\\r\n",
      "Device & 51.43 & 33.96 & 40.91\\\\\r\n",
      "Operating System & 91.18 & 46.97 & 62.0\\\\\r\n",
      "Website & 28.57 & 51.28 & 36.7\\\\\r\n",
      "Algorithm & 0 & 0.0 & 0\\\\\r\n",
      "overall & 70.58 & 70.22 & 70.4\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  21775.404473781586 secs\r\n",
      "---------epoch count:  2\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11144 phrases; correct: 9226.\r\n",
      "accuracy:  98.35%; precision:  82.79%; recall:  82.38%; FB1:  82.58\r\n",
      "        Algorithm: precision:  83.33%; recall:  12.20%; FB1:  21.28 foundGuessed:  6\r\n",
      "      Application: precision:  81.43%; recall:  89.21%; FB1:  85.15 foundGuessed:  1422\r\n",
      "            Class: precision:  84.33%; recall:  73.93%; FB1:  78.79 foundGuessed:  1187\r\n",
      "       Code_Block: precision:  74.84%; recall:  69.88%; FB1:  72.27 foundGuessed:  775\r\n",
      "   Data_Structure: precision:  75.16%; recall:  94.25%; FB1:  83.63 foundGuessed:  785\r\n",
      "        Data_Type: precision:  87.97%; recall:  89.23%; FB1:  88.60 foundGuessed:  424\r\n",
      "           Device: precision:  90.91%; recall:  75.38%; FB1:  82.42 foundGuessed:  165\r\n",
      "        File_Name: precision:  86.14%; recall:  89.10%; FB1:  87.60 foundGuessed:  332\r\n",
      "        File_Type: precision:  91.24%; recall:  82.29%; FB1:  86.53 foundGuessed:  331\r\n",
      "         Function: precision:  80.15%; recall:  84.25%; FB1:  82.15 foundGuessed:  821\r\n",
      "     HTML_XML_Tag: precision:  78.45%; recall:  68.93%; FB1:  73.39 foundGuessed:  181\r\n",
      "         Language: precision:  90.18%; recall:  96.06%; FB1:  93.03 foundGuessed:  784\r\n",
      "          Library: precision:  82.67%; recall:  73.23%; FB1:  77.67 foundGuessed:  652\r\n",
      " Operating_System: precision:  82.53%; recall:  80.12%; FB1:  81.31 foundGuessed:  166\r\n",
      "User_Interface_Element: precision:  92.58%; recall:  81.65%; FB1:  86.77 foundGuessed:  822\r\n",
      "            Value: precision:  88.64%; recall:  79.14%; FB1:  83.62 foundGuessed:  625\r\n",
      "         Variable: precision:  74.07%; recall:  86.62%; FB1:  79.85 foundGuessed:  1311\r\n",
      "          Version: precision:  88.26%; recall:  90.66%; FB1:  89.44 foundGuessed:  264\r\n",
      "          Website: precision:  86.81%; recall:  74.53%; FB1:  80.20 foundGuessed:  91\r\n",
      "-----------------------------------sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3851 phrases; correct: 2886.\r\n",
      "accuracy:  97.59%; precision:  74.94%; recall:  74.81%; FB1:  74.87\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  1\r\n",
      "      Application: precision:  72.44%; recall:  85.26%; FB1:  78.33 foundGuessed:  479\r\n",
      "            Class: precision:  77.07%; recall:  69.22%; FB1:  72.93 foundGuessed:  458\r\n",
      "       Code_Block: precision:  62.50%; recall:  62.91%; FB1:  62.71 foundGuessed:  304\r\n",
      "   Data_Structure: precision:  77.89%; recall:  92.71%; FB1:  84.66 foundGuessed:  294\r\n",
      "        Data_Type: precision:  88.89%; recall:  86.49%; FB1:  87.67 foundGuessed:  108\r\n",
      "           Device: precision:  73.47%; recall:  67.92%; FB1:  70.59 foundGuessed:  49\r\n",
      "        File_Name: precision:  91.61%; recall:  80.37%; FB1:  85.62 foundGuessed:  143\r\n",
      "        File_Type: precision:  91.92%; recall:  70.54%; FB1:  79.82 foundGuessed:  99\r\n",
      "         Function: precision:  68.29%; recall:  73.68%; FB1:  70.89 foundGuessed:  287\r\n",
      "     HTML_XML_Tag: precision:  68.29%; recall:  53.85%; FB1:  60.22 foundGuessed:  41\r\n",
      "         Language: precision:  81.58%; recall:  87.08%; FB1:  84.24 foundGuessed:  190\r\n",
      "          Library: precision:  70.04%; recall:  64.59%; FB1:  67.21 foundGuessed:  237\r\n",
      " Operating_System: precision:  92.19%; recall:  89.39%; FB1:  90.77 foundGuessed:  64\r\n",
      "User_Interface_Element: precision:  84.91%; recall:  76.06%; FB1:  80.24 foundGuessed:  318\r\n",
      "            Value: precision:  83.15%; recall:  67.89%; FB1:  74.75 foundGuessed:  178\r\n",
      "         Variable: precision:  60.09%; recall:  73.28%; FB1:  66.03 foundGuessed:  461\r\n",
      "          Version: precision:  82.05%; recall:  86.49%; FB1:  84.21 foundGuessed:  117\r\n",
      "          Website: precision:  78.26%; recall:  46.15%; FB1:  58.06 foundGuessed:  23\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_so.py\", line 646, in <module>\r\n",
      "    train_model(model, step_lr_scheduler, optimizer, train_data, dev_data, test_data)\r\n",
      "  File \"train_so.py\", line 541, in train_model\r\n",
      "    best_dev_F, new_dev_F, save = evaluating(model, dev_data, best_dev_F, epoch, phase_name) \r\n",
      "  File \"train_so.py\", line 396, in evaluating\r\n",
      "    print_result.print_result(eval_result, epoch_count, parameters[\"sorted_entity_list_file_name\"], parameters[\"entity_category_code\"], parameters[\"entity_category_human_language\"])\r\n",
      "  File \"/root/Project/StackOverflowNER/code/Attentive_BiLSTM/print_result.py\", line 17, in print_result\r\n",
      "    with open(sorted_entity_list_file) as f:\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'sorted_entity_list_by_count_all.json'\r\n",
      ".59\\\\\r\n",
      "Operating System & 92.19 & 89.39 & 90.77\\\\\r\n",
      "Website & 78.26 & 46.15 & 58.06\\\\\r\n",
      "Algorithm & 0.0 & 0.0 & 0\\\\\r\n",
      "overall & 74.94 & 74.81 & 74.87\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  15856.095844984055 secs\r\n",
      "---------epoch count:  3\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11093 phrases; correct: 9688.\r\n",
      "accuracy:  98.76%; precision:  87.33%; recall:  86.50%; FB1:  86.92\r\n",
      "        Algorithm: precision:  80.95%; recall:  41.46%; FB1:  54.84 foundGuessed:  21\r\n",
      "      Application: precision:  82.34%; recall:  93.07%; FB1:  87.38 foundGuessed:  1467\r\n",
      "            Class: precision:  83.71%; recall:  84.27%; FB1:  83.99 foundGuessed:  1363\r\n",
      "       Code_Block: precision:  79.26%; recall:  80.12%; FB1:  79.69 foundGuessed:  839\r\n",
      "   Data_Structure: precision:  85.74%; recall:  93.13%; FB1:  89.28 foundGuessed:  680\r\n",
      "        Data_Type: precision:  92.24%; recall:  93.78%; FB1:  93.00 foundGuessed:  425\r\n",
      "           Device: precision:  91.67%; recall:  82.91%; FB1:  87.07 foundGuessed:  180\r\n",
      "        File_Name: precision:  91.77%; recall:  93.77%; FB1:  92.76 foundGuessed:  328\r\n",
      "        File_Type: precision:  89.81%; recall:  91.28%; FB1:  90.54 foundGuessed:  373\r\n",
      "         Function: precision:  87.82%; recall:  83.99%; FB1:  85.86 foundGuessed:  747\r\n",
      "     HTML_XML_Tag: precision:  94.94%; recall:  72.82%; FB1:  82.42 foundGuessed:  158\r\n",
      "         Language: precision:  96.19%; recall:  92.53%; FB1:  94.32 foundGuessed:  708\r\n",
      "          Library: precision:  88.97%; recall:  66.85%; FB1:  76.34 foundGuessed:  553\r\n",
      " Operating_System: precision:  80.63%; recall:  90.06%; FB1:  85.08 foundGuessed:  191\r\n",
      "User_Interface_Element: precision:  90.83%; recall:  92.49%; FB1:  91.65 foundGuessed:  949\r\n",
      "            Value: precision:  93.58%; recall:  85.43%; FB1:  89.32 foundGuessed:  639\r\n",
      "         Variable: precision:  85.05%; recall:  86.80%; FB1:  85.92 foundGuessed:  1144\r\n",
      "          Version: precision:  95.49%; recall:  90.66%; FB1:  93.01 foundGuessed:  244\r\n",
      "          Website: precision:  97.62%; recall:  77.36%; FB1:  86.32 foundGuessed:  84\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3834 phrases; correct: 2806.\r\n",
      "accuracy:  97.38%; precision:  73.19%; recall:  72.73%; FB1:  72.96\r\n",
      "        Algorithm: precision:  33.33%; recall:   6.25%; FB1:  10.53 foundGuessed:  3\r\n",
      "      Application: precision:  68.05%; recall:  88.45%; FB1:  76.92 foundGuessed:  529\r\n",
      "            Class: precision:  69.50%; recall:  68.82%; FB1:  69.16 foundGuessed:  505\r\n",
      "       Code_Block: precision:  57.61%; recall:  58.94%; FB1:  58.27 foundGuessed:  309\r\n",
      "   Data_Structure: precision:  84.36%; recall:  83.00%; FB1:  83.67 foundGuessed:  243\r\n",
      "        Data_Type: precision:  82.76%; recall:  86.49%; FB1:  84.58 foundGuessed:  116\r\n",
      "           Device: precision:  69.09%; recall:  71.70%; FB1:  70.37 foundGuessed:  55\r\n",
      "        File_Name: precision:  86.08%; recall:  83.44%; FB1:  84.74 foundGuessed:  158\r\n",
      "        File_Type: precision:  86.24%; recall:  72.87%; FB1:  78.99 foundGuessed:  109\r\n",
      "         Function: precision:  76.21%; recall:  65.04%; FB1:  70.18 foundGuessed:  227\r\n",
      "     HTML_XML_Tag: precision:  64.44%; recall:  55.77%; FB1:  59.79 foundGuessed:  45\r\n",
      "         Language: precision:  85.03%; recall:  79.78%; FB1:  82.32 foundGuessed:  167\r\n",
      "          Library: precision:  74.85%; recall:  48.64%; FB1:  58.96 foundGuessed:  167\r\n",
      " Operating_System: precision:  78.21%; recall:  92.42%; FB1:  84.72 foundGuessed:  78\r\n",
      "User_Interface_Element: precision:  77.78%; recall:  80.85%; FB1:  79.28 foundGuessed:  369\r\n",
      "            Value: precision:  80.11%; recall:  68.35%; FB1:  73.76 foundGuessed:  186\r\n",
      "         Variable: precision:  60.14%; recall:  70.63%; FB1:  64.96 foundGuessed:  444\r\n",
      "          Version: precision:  91.35%; recall:  85.59%; FB1:  88.37 foundGuessed:  104\r\n",
      "          Website: precision:  95.00%; recall:  48.72%; FB1:  64.41 foundGuessed:  20\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\\begin{table}[htbp]\r\n",
      "\\centering\r\n",
      "\\begin{tabular}{|c|c|c|c|}\r\n",
      "\\hline\r\n",
      " & Precision & Recall & F1\\\\\r\n",
      "\\hline\r\n",
      "Class & 69.5 & 68.82 & 69.16\\\\\r\n",
      "Application & 68.05 & 88.45 & 76.92\\\\\r\n",
      "Variable & 60.14 & 70.63 & 64.96\\\\\r\n",
      "User Interface Element & 77.78 & 80.85 & 79.28\\\\\r\n",
      "Code Block & 57.61 & 58.94 & 58.27\\\\\r\n",
      "Function & 76.21 & 65.04 & 70.18\\\\\r\n",
      "Language & 85.03 & 79.78 & 82.32\\\\\r\n",
      "Library & 74.85 & 48.64 & 58.96\\\\\r\n",
      "Value & 80.11 & 68.35 & 73.76\\\\\r\n",
      "Data Structure & 84.36 & 83.0 & 83.67\\\\\r\n",
      "Data Type & 82.76 & 86.49 & 84.58\\\\\r\n",
      "File Type & 86.24 & 72.87 & 78.99\\\\\r\n",
      "File Name & 86.08 & 83.44 & 84.74\\\\\r\n",
      "Version & 91.35 & 85.59 & 88.37\\\\\r\n",
      "HTML XML Tag & 64.44 & 55.77 & 59.79\\\\\r\n",
      "Device & 69.09 & 71.7 & 70.37\\\\\r\n",
      "Operating System & 78.21 & 92.42 & 84.72\\\\\r\n",
      "Website & 95.0 & 48.72 & 64.41\\\\\r\n",
      "Algorithm & 33.33 & 6.25 & 10.53\\\\\r\n",
      "overall & 73.19 & 72.73 & 72.96\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  21970.68362045288 secs\r\n",
      "total time in training:  51424.883888959885\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/root/Project/StackOverflowNER/code/Attentive_BiLSTM/')\n",
    "!cat running.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: epoch: 1 P: 70.58 R: 70.22 F1: 70.4\r\n",
      "test: epoch: 2 P: 74.94 R: 74.81 F1: 74.87\r\n",
      "test: epoch: 3 P: 73.19 R: 72.73 F1: 72.96\r\n"
     ]
    }
   ],
   "source": [
    "!cat perf_per_epoch_2020-10-19_9911_1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the results in the paper, our trainig model\n",
    "\n",
    "![paperSoftNER](./notebook_resources/paperSoftNER.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAoCF2YruZ1n",
    "nbpresent": {
     "id": "a607c108-2092-43cd-9bcd-2ac565bef1af"
    }
   },
   "source": [
    "## Evaluate The SoftNER Model's Performance on Leetcode Sentences\n",
    "\n",
    "\n",
    "<!-- Something -->\n",
    "\n",
    "\n",
    "\n",
    "Here gives an example of how to use SoftNER to indentify named entities in article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Identify Named Entities  \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/BERT_NER/')\n",
    "\n",
    "from utils_preprocess import *\n",
    "from utils_preprocess.format_markdown import *\n",
    "from utils_preprocess.anntoconll import *\n",
    "\n",
    "import glob\n",
    "\n",
    "from utils_ctc import *\n",
    "from utils_ctc.prediction_ctc import *\n",
    "\n",
    "import softner_segmenter_preditct_from_file\n",
    "import softner_ner_predict_from_fil\n",
    "\n",
    "from E2E_SoftNER import read_file, merge_all_conll_files, create_segmenter_input, create_ner_input\n",
    "\n",
    "\n",
    "# input file\n",
    "input_file = \"xml_filted_body.txt\"\n",
    "base_temp_dir = \"temp_files/\"\n",
    "standoff_folder = \"temp_files/standoff_files/\"\n",
    "# dir of code recognizer\n",
    "conll_folder = \"temp_files/conll_files/\"\n",
    "conll_file = \"temp_files/conll_format_txt.txt\"\n",
    "# dir of entity segmenter\n",
    "segmenter_input_file = \"temp_files/segmenter_ip.txt\"\n",
    "segmenter_output_file = \"temp_files/segemeter_preds.txt\"\n",
    "# input features & SoftNER prediction \n",
    "ner_input_file = \"temp_files/ner_ip.txt\"\n",
    "ner_output_file = \"ner_preds.txt\"\n",
    "\n",
    "if not os.path.exists(base_temp_dir): os.makedirs(base_temp_dir)\n",
    "if not os.path.exists(standoff_folder): os.makedirs(standoff_folder)\n",
    "if not os.path.exists(conlll_folder): os.makedirs(conlll_folder)\n",
    "\n",
    "# read sentences and tokenize the sentences\n",
    "read_file(input_file, standoff_folder)\n",
    "\n",
    "# Code Recognizer\n",
    "convert_standoff_to_conll(standoff_folder, conll_folder)\n",
    "merge_all_conll_files(conll_folder, conll_file)\n",
    "create_segmenter_input(conll_file, segmenter_input_file, ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features)\n",
    "\n",
    "# Entity Segmenter\n",
    "predict_segments(segmenter_input_file, segmenter_output_file)\n",
    "create_ner_input(segmenter_output_file, ner_input_file, ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features)\n",
    "\n",
    "# recognize named entities\n",
    "softner_ner_predict_from_file.predict_entities(ner_input_file, ner_output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and Solutions\n",
    "\n",
    "<!-- challenges & solutions -->\n",
    "\n",
    "- The size of the dataset is more than 30G. Quote is limited when running codes on Colab with the mounted Google Drive.\n",
    "    - We set up an instance on Google Cloud\n",
    "    - Built a Jupyter server\n",
    "- Bugs in the source codes\n",
    "    - Encoding problem when read or write files\n",
    "    - When running the codes in Jupyter\n",
    "    - A typo\n",
    "    - Incompatible version of modules\n",
    "- Several essential files are missing in the original folder\n",
    "    - We have contacted the author multiple times. Thank you Jeniya!\n",
    "- Instruction to set up the model is not clear\n",
    "    - Code review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution\n",
    "\n",
    "<!-- Acknowledgement -->\n",
    "\n",
    "**Changheng Liou**\n",
    "- Build up a Jupyter server, which directs to the instance in Google Cloud\n",
    "- Crawling the sentences in Leetcode discussion\n",
    "- Analyze the SoftNER model architecture\n",
    "- Code review\n",
    "- Responsible for presenting our work in the final presentation\n",
    "- Complete the report\n",
    "\n",
    "**Zhiying Cui**\n",
    "- Provide a server in Google Cloud and set up the environment\n",
    "- Debug the source codes \n",
    "- Analyze the auxiliary models\n",
    "- Code review\n",
    "- Responsible for answering questions in the final presentation\n",
    "- Complete the report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMrS5Twng5Fs",
    "nbpresent": {
     "id": "e268745f-5723-4a9b-bab7-fa5c14569f97"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. Jeniya Tabassum et al., [Code and Named Entity Recognition in StackOverﬂow](https://arxiv.org/abs/2005.01634)\n",
    "2. Jacob Devlin et al., [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "3. [StackOverflowNER](https://github.com/jeniyat/StackOverflowNER)\n",
    "4. [Pre-trained BERTOverflow](https://huggingface.co/jeniya/BERTOverflow#)\n",
    "5. [BERT](https://huggingface.co/transformers/model_doc/bert.html)\n",
    "6. [transformers](https://github.com/huggingface/transformers)\n",
    "7. [fastText](https://github.com/facebookresearch/fastText)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
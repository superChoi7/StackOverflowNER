{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IHBeCrOPek7",
    "nbpresent": {
     "id": "71880bb8-62db-43cb-b4a3-b68514ba2d4e"
    }
   },
   "source": [
    "# Named Entity Recognition on Stack Overflow\n",
    "\n",
    "Name: Changheng Liou, Zhiying Cui\n",
    "\n",
    "NetID: cl5533, zc2191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rri7MbidwfcN",
    "nbpresent": {
     "id": "29629440-9fc9-43a6-a4f3-06826bc8dcb1"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "As increasing interest in studying snippets composed of natural languages and computer codes, named entity recognization (NER) for computer programming languages becomes a promising application. \n",
    "\n",
    "Though large numbers of programming texts are readily available on the Internet, there is still a lack of fundamental natural language processing (NLP) techniques for identifying code tokens or software-related named entities that appear within natural language sentences. \n",
    "Another challenge in NER for the computer programming domain is that name entities are often ambiguous. It is hard to refer a word to a technical programming concept or common language. For example, \"list\" not only refers to a data structure but also is used as a variable name. They often have implicit reliance on the accompanied code snippets.\n",
    "\n",
    "[Tabassum et al.](https://arxiv.org/abs/2005.01634) did a comprehensive study in this area. They introduced a new StackOverflow NER corpus for the social computer programming domain, which consists of 15,372 sentences annotated with 20 fine-grained entity types. They proposed a named entity recognizer SoftNER model, which incorporated a context-independent code token classiﬁer with corpus-level features to improve the BERT based tagging model. The evaluation showed that the SoftNER outperforms on identifying software-related named entities than existing models such as fine-tuned BERT, BiLSTEM-CRF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcI7WO6-bxn1",
    "nbpresent": {
     "id": "993b8697-34f5-4ba9-b9df-6b3089cc974d"
    }
   },
   "source": [
    "## Goal of This Work\n",
    "\n",
    "- Identify named entities on software-related texts. Classify them into 20 types of entities.\n",
    "- Evaluate the SoftNER model's performance on other sources of technical articles, such as Leetcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxMcQbbDhI_P"
   },
   "source": [
    "## Development Environmet\n",
    "\n",
    "- Framework: PyTorch\n",
    "- Environment: Jupyter server on Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py36/bin/python\n",
      "3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:09:42) \n",
      "[GCC 7.5.0]\n",
      "sys.version_info(major=3, minor=6, micro=11, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI_TMjMNwlPh",
    "nbpresent": {
     "id": "01b40fdd-08a9-4c27-9ea9-21caa53e3d27"
    }
   },
   "source": [
    "- Directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "├── data\r\n",
      "├── Huggingface_SoftNER\r\n",
      "├── leetcode-discuss.txt\r\n",
      "├── main.ipynb\r\n",
      "├── StackOverflowNER\r\n",
      "└── zipFiles\r\n",
      "\r\n",
      "4 directories, 2 files\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/root/Project/')\n",
    "!tree -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dirProject](./notebook_resources/dirProject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Directory of the SoftNER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "├── code\r\n",
      "│   ├── Attentive_BiLSTM\r\n",
      "│   ├── BERT_NER\r\n",
      "│   ├── DataReader\r\n",
      "│   ├── Readme.md\r\n",
      "│   └── SOTokenizer\r\n",
      "├── License\r\n",
      "├── Readme.md\r\n",
      "└── resources\r\n",
      "    ├── annotated_ner_data\r\n",
      "    └── pretrained_word_vectors\r\n",
      "\r\n",
      "8 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/root/Project/StackOverflowNER')\n",
    "!tree -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dirSoftNER](./notebook_resources/dirSoftNER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLie0qd3eFlX",
    "nbpresent": {
     "id": "382174ac-3857-48ed-bd4a-937463e46433"
    }
   },
   "source": [
    "## Annotated StackOverﬂow Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEluwFCZeTcK",
    "nbpresent": {
     "id": "1a4f0dd7-9e42-41b3-a1ab-14b82991a9b9"
    }
   },
   "source": [
    "### Construction of StackOverﬂow NER corpus\n",
    "\n",
    "Authors introduce a new StackOverflow NER corpus, they\n",
    "- Selected **1,237** question-answer threads from StackOverﬂow 10-year archive (from September 2008 to March 2018).\n",
    "- Manually annotated them with 20 types of entities.\n",
    "    - 8 code entities: CLASS, VARIABLE, IN LINE CODE, FUNCTION, LIBRARY, VALUE, DATA TYPE, HTML XML TAG\n",
    "    - 12 natural language entities: APPLICATION, UI ELEMENT, LANGUAGE, DATA STRUCTURE, ALGORITHM, FILE TYPE, FILE NAME, VERSION, DEVICE, OS, WEBSITE, USER NAME\n",
    "- Corpus was annotated by annotators. Because of the low rate of code-related entities marked by the StackOverﬂow users, and the high possibility of mistakenly enclosed texts that are actually code-related.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2bo3BiSRvQE",
    "nbpresent": {
     "id": "0e904198-95a3-491e-a664-308045b9d783"
    }
   },
   "source": [
    "### StackOverflow tokenizer - SOTokenizer\n",
    "\n",
    "Authors implemented a custom tokenizer `SOTokenizer` specifically for texts with codes and common languages;  existing tokenizers, such as CMU Twokenizer, Stanford TweetTokenizer and NLTK Twitter tokenizer often mistakenly split code, for example:\n",
    "```\n",
    "txScope.complete() => [\"txScope\", \".\", \"complete\", \"(\", \")\"]\n",
    "std::condition_variable => [\"std\", \":\", \":\", \"condition_variable\"]\n",
    "math.h => [\"math\", \".\", \"h\"]\n",
    "<html> => [\"<\", \"html\", \">\"]\n",
    "a == b => [\"a\", \"=\", \"=\", \"b\"]\n",
    "```\n",
    "\n",
    "On the other hand, `SOTokenizer` works well on texts with codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1602493738491,
     "user": {
      "displayName": "Chang-Heng Liou",
      "photoUrl": "",
      "userId": "08046120486785659898"
     },
     "user_tz": -480
    },
    "id": "WuNgw9wZR6lG",
    "nbpresent": {
     "id": "99c67626-72eb-4774-b6c5-577237dd8679"
    },
    "outputId": "6935e6e7-d620-4532-817d-9d6ed54d20c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std::condition_variable \n",
      "tokens:  ['std::condition_variable'] \n",
      "\n",
      "I do think that the request I send to my API should be more like {post=>{\"kind\"=>\"GGG\"}} and not {\"kind\"=>\"GGG\"}. \n",
      "tokens:  ['I', 'do', 'think', 'that', 'the', 'request', 'I', 'send', 'to', 'my', 'API', 'should', 'be', 'more', 'like', ' { post=> { \"kind\"=>\"GGG\" }  } ', 'and', 'not', ' { \"kind\"=>\"GGG\" } ', '.'] \n",
      "\n",
      "**Basic idea:** If we start from ```sx,sy```, it will be hard to find ```tx, ty```. If we start from ```tx,ty```, we can find only one path to go back to ```sx, sy```. I cut down one by one at first and I got TLE. So I came up with remainder.  **First line:** if 2 target points are still bigger than 2 starting point, we reduce target points. **Second line:** check if we reduce target points to (x, y+kx) or (x+ky, y)  **Time complexity** I will say ```O(logN)``` where ```N = max(tx,ty)```.  **C++:** ```cpp     bool reachingPoints(int sx, int sy, int tx, int ty) {         while (sx < tx && sy < ty)             if (tx < ty) ty %= tx;             else tx %= ty;         return sx == tx && sy <= ty && (ty - sy) % sx == 0 ||                sy == ty && sx <= tx && (tx - sx) % sy == 0;     } \n",
      "tokens:  ['**', 'Basic', 'idea:**', 'If', 'we', 'start', 'from', '```sx', ',', 'sy```', ',', 'it', 'will', 'be', 'hard', 'to', 'find', '```tx', ',', 'ty```', '.', 'If', 'we', 'start', 'from', '```tx', ',', 'ty```', ',', 'we', 'can', 'find', 'only', 'one', 'path', 'to', 'go', 'back', 'to', '```sx', ',', 'sy```', '.', 'I', 'cut', 'down', 'one', 'by', 'one', 'at', 'first', 'and', 'I', 'got', 'TLE', '.', 'So', 'I', 'came', 'up', 'with', 'remainder', '.', '**', 'First', 'line:**', 'if', '2', 'target', 'points', 'are', 'still', 'bigger', 'than', '2', 'starting', 'point', ',', 'we', 'reduce', 'target', 'points', '.', '**', 'Second', 'line:**', 'check', 'if', 'we', 'reduce', 'target', 'points', 'to', '(', 'x', ',', 'y+kx )', 'or', '(', 'x+ky', ',', 'y )', '**', 'Time', 'complexity**', 'I', 'will', 'say', '```O(logN)```', 'where', '```N', '=', 'max(tx,ty)```.', '**', 'C++', ':**', '```cpp', 'bool', 'reachingPoints(int sx, int sy, int tx, int ty)', '{', 'while', '(', 'sx', '<', 'tx', '&&', 'sy', '<', 'ty )', 'if', '(', 'tx', '<', 'ty )', 'ty', '%', '=', 'tx', ';', 'else', 'tx', '%', '=', 'ty', ';', 'return', 'sx', '==', 'tx', '&&', 'sy', '<=', 'ty', '&&', '(', 'ty', '-', 'sy )', '%', 'sx', '==', '0', '||', 'sy', '==', 'ty', '&&', 'sx', '<=', 'tx', '&&', '(', 'tx', '-', 'sx )', '%', 'sy', '==', '0', ';', '}'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SOTokenizer \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/SOTokenizer')\n",
    "\n",
    "import stokenizer\n",
    "\n",
    "# example 1 - code snippets\n",
    "sentence = 'std::condition_variable'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n",
    "\n",
    "# example 2 - sentences from StackOverflow\n",
    "sentence = 'I do think that the request I send to my API should be more like {post=>{\"kind\"=>\"GGG\"}} and not {\"kind\"=>\"GGG\"}.'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n",
    "\n",
    "# example 3 - sentences from Leetcode (markdown format)\n",
    "sentence = '**Basic idea:** If we start from ```sx,sy```, it will be hard to find ```tx, ty```. If we start from ```tx,ty```, we can find only one path to go back to ```sx, sy```. I cut down one by one at first and I got TLE. So I came up with remainder.  **First line:** if 2 target points are still bigger than 2 starting point, we reduce target points. **Second line:** check if we reduce target points to (x, y+kx) or (x+ky, y)  **Time complexity** I will say ```O(logN)``` where ```N = max(tx,ty)```.  **C++:** ```cpp     bool reachingPoints(int sx, int sy, int tx, int ty) {         while (sx < tx && sy < ty)             if (tx < ty) ty %= tx;             else tx %= ty;         return sx == tx && sy <= ty && (ty - sy) % sx == 0 ||                sy == ty && sx <= tx && (tx - sx) % sy == 0;     }'\n",
    "tokens = stokenizer.tokenize(sentence)\n",
    "print(sentence, \"\\ntokens: \", tokens, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkZ66Q-Ra1mt",
    "nbpresent": {
     "id": "10bd16f1-a91c-484a-b154-ed2e670e4d59"
    }
   },
   "source": [
    "### Load annotated files\n",
    "\n",
    "Autours provided a function to read the annotated dataset.\n",
    "- Read the dataset using `loader_so.py` from `DataReader`.\n",
    "- By default the `loader_so_text` function merges the following 6 entities to 3.\n",
    "\n",
    "```\n",
    "\"Library_Function\" -> \"Function\"\n",
    "\"Function_Name\" -> \"Function\"\n",
    "\n",
    "\"Class_Name\" -> \"Class\"\n",
    "\"Library_Class\" -> \"Class\"\n",
    "\n",
    "\"Library_Variable\" -> \"Variable\"\n",
    "\"Variable_Name\" -> \"Variable\"\n",
    "\n",
    "\"Website\" -> \"Website\"\n",
    "\"Organization\" -> \"Website\"\n",
    "```\n",
    "\n",
    "Arguments settings\n",
    "- `merge_tag=False`: skip the merging by setting.\n",
    "- `replace_low_freq_tags=False`: skip the conversion. By default the `loader_so_text` function converts the 5 low frequency entiies as \"O\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 1622,
     "status": "ok",
     "timestamp": 1602420374685,
     "user": {
      "displayName": "Zhiying Cui",
      "photoUrl": "",
      "userId": "00010876004313184189"
     },
     "user_tz": -480
    },
    "id": "NhLsDflQa81v",
    "nbpresent": {
     "id": "faf7cbb1-c9ab-4a20-b0ed-636610af5314"
    },
    "outputId": "7b4a122f-3e5e-49f3-c6d4-b56189841471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\n",
      "Max len sentences has 92 words\n",
      "------------------------------------------------------------\n",
      "\n",
      "Training dataset (preview first 5 lines):\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'B-Data_Structure']] \n",
      "\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'O']] \n",
      "\n",
      "[['If', 'O', 'O'], ['I', 'O', 'O'], ['would', 'O', 'O'], ['have', 'O', 'O'], ['2', 'O', 'O'], ['tables', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "[['How', 'O', 'O'], ['do', 'O', 'O'], ['I', 'O', 'O'], ['get', 'O', 'O'], ['this', 'O', 'O'], ['result', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "[['The', 'O', 'O'], ['following', 'O', 'O'], ['query', 'O', 'O'], ['needs', 'O', 'O'], ['to', 'O', 'O'], ['be', 'O', 'O'], ['adjusted', 'O', 'O'], [',', 'O', 'O'], ['but', 'O', 'O'], ['I', 'O', 'O'], ['dont', 'O', 'O'], ['know', 'O', 'O'], ['how', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['SQLFIDDLE', 'O', 'B-Application'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "[['SQLFIDDLE', 'O', 'O'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "[['SQLFIDDLE', 'O', 'O'], [':', 'O', 'O'], ['http://sqlfiddle.com/#!9/11093', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "[['You', 'O', 'O'], ['are', 'O', 'O'], ['very', 'O', 'O'], ['close', 'O', 'O'], ['.', 'O', 'O']] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load annotated data \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/DataReader')\n",
    "\n",
    "import loader_so\n",
    "\n",
    "# dir of dataset\n",
    "path_to_file = \"../../resources/annotated_ner_data/StackOverflow/train.txt\"\n",
    "\n",
    "# merge entities (default)\n",
    "all_sentences = loader_so.loader_so_text(path_to_file)\n",
    "\n",
    "# skip merging\n",
    "all_sentences_no_merge = loader_so.loader_so_text(path_to_file, replace_low_freq_tags= False)\n",
    "\n",
    "# skip conversion\n",
    "all_sentences_no_conversion = loader_so.loader_so_text(path_to_file, replace_low_freq_tags= False)\n",
    "\n",
    "print(\"\\nTraining dataset (preview first 5 lines):\")\n",
    "for i in range(5):\n",
    "    print(all_sentences[i], '\\n')\n",
    "    print(all_sentences_no_merge[i], '\\n')\n",
    "    print(all_sentences_no_conversion[i], '\\n')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A2V27Ujg5Fn",
    "nbpresent": {
     "id": "d1511b90-dbd8-4fc2-a1a5-97b4219de2c6"
    }
   },
   "source": [
    "# SoftNER Model Architecture\n",
    "\n",
    "1. **Input embedding layer**: Extract contextualized embeddings from the BERT model and two new domain-specific embeddings for each word in the input sentence.\n",
    "2. **Embedding attention layer**: Combine the three word embeddings using an attention network.\n",
    "3. **Linear-CRF layer**: Predict the entity type of each word using the attentive word representations from the previous layer.\n",
    "\n",
    "![modelArchitecture](./notebook_resources/modelArchitecture.png)\n",
    "\n",
    "The SoftNER model and two auxiliary models are trained separately. We can train the two standalone modules by following the instructions from [Running BERT NER Model](https://github.com/jeniyat/StackOverflowNER/tree/master/code#running-bert-ner-model). Noted that the modified transformers can be found [here](https://github.com/jeniyat/Huggingface_SoftNER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gobPwiGfg5Fp",
    "nbpresent": {
     "id": "a50d0406-2a0f-4667-ba01-fa7cf49298db"
    }
   },
   "source": [
    "## Input embeddings\n",
    "\n",
    "- **BERT**, which transforms a token into contextual vector representation. [(Devlin et al.)](https://arxiv.org/pdf/1810.04805)\n",
    "- **Code Recognizer**, which represents whether a given word is a code entity or not regardless of context.\n",
    "- **Entity Segmenter**, which predicts whether a given word is in the one of pre-defined named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgo2M1RoA_cB",
    "nbpresent": {
     "id": "c020a8fb-ff61-4479-aecf-5ca4f8004ed3"
    }
   },
   "source": [
    "### In-domain Word Embeddings (BERT)\n",
    "\n",
    "Wikipedia text is unsuitable for computer programming context. So, authors pre-trained three in-domain word embeddings on 152 million sentences from [StackOverflow 10-year archive](https://archive.org/details/stackexchange), including BERT (BERTOverflow), ELMo (ELMoVerflow), and GloVe (GloVerflow).\n",
    "The results showed that the NER model with BERT outperformed on identifying entities than the others. Thus, we chose BERT as our in-domain word embedding.\n",
    "\n",
    "The pretrained BERT is saved in `/root/Project/StackOverflowNER/pretrained_word_vectors/BERT/`\n",
    "\n",
    "<!-- BERT has 12 layers, hidden size 768, self-attention heads 12, total parameters 110M -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-EZ9-tACPKd",
    "nbpresent": {
     "id": "d3bd712f-2dbb-4ea6-a7ce-af689d35ad19"
    }
   },
   "source": [
    "### Context-independent Code Recognition (Code Recognizer)\n",
    "\n",
    "**Goal**: A code recognition module that predicts the probability of how likely a word is a code token without considering any contextual information. **Code Recognizer is a binary classifier, which outputs 0 or 1 depends on if the word is a code piece or not.** \n",
    "\n",
    "The implementation details are as follows:\n",
    "\n",
    "1. Input features: unigram word and 6-gram character probabilities from two language models that are trained on the Gigaword corpus and all the code-snippets in the StackOverflow corpus.\n",
    "2. Transform each ngram probability into a k-dimensional vector using Gaussian binning, which can improve the performance of neural models using numeric features.\n",
    "3. Feed the vectorized features into a linear layer and concatenate the output with pretrained FastText character-level embeddings.\n",
    "4. Pass the outputs through another hidden layer with sigmoid activation, and see if the output probability is greater than 0.5.\n",
    "\n",
    "The directory of the Code Recognizer is `/root/Project/StackOverflowNER/code/BERT_NER/`. Since the source codes are too long, we picked out the training function to see how it was implemented and ran the training process in the server.\n",
    "\n",
    "**Parameters**\n",
    "- `LR=0.0015`: learning rate \n",
    "- `epochs=70`: epochs\n",
    "- `word_dim=300`: embedding dimension, the same as weights dimension in fastText\n",
    "- `hidden_layer_1_dim=30`: dimension of hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [SoftNER Model] A binary classifier that output if a word is a code-snippet or not. \"\"\"\n",
    "\n",
    "class NeuralClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_feat_dim, target_label_dim, vocab_size, pre_word_embeds=None):\n",
    "        super(NeuralClassifier, self).__init__()\n",
    "        \n",
    "        hidden_layer_node = parameters_ctc['hidden_layer_1_dim']\n",
    "        self.Linear_Layer_1=torch.nn.Linear(input_feat_dim, hidden_layer_node)\n",
    "        self.Tanh_Layer=torch.nn.Tanh()\n",
    "\n",
    "        self.Word_Embeds = torch.nn.Embedding(vocab_size, parameters_ctc['word_dim'])\n",
    "        if pre_word_embeds.any():\n",
    "            self.Word_Embeds.weight = torch.nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "        self.Linear_Layer_2=torch.nn.Linear(hidden_layer_node, target_label_dim)\n",
    "        self.Linear_Layer_2=torch.nn.Linear(hidden_layer_node, hidden_layer_node)\n",
    "        self.Linear_Layer_3=torch.nn.Linear(hidden_layer_node+parameters_ctc['word_dim'], target_label_dim)\n",
    "        self.Softmax_Layer=torch.nn.Softmax(dim=1)\n",
    "\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, features, word_ids):\n",
    "        scores = self.get_scores(features, word_ids)\n",
    "        if torch.cuda.is_available():\n",
    "            scores_ = scores.cpu().data.numpy()\n",
    "        else:\n",
    "            scores_ = scores.data.numpy()\n",
    "        predictions = [np.argmax(sc) for sc in scores_]\n",
    "        return scores, predictions\n",
    "    \n",
    "    \"\"\" Main feed forward logic to get the final probability \"\"\"\n",
    "    def get_scores(self, features, word_ids):\n",
    "        features_x = Variable(torch.FloatTensor(features).to(device))\n",
    "        word_ids=word_ids.to(device)\n",
    "        # the first linear layer with unigram and 6-gram character probabilities from step 1\n",
    "        liner1_op = self.Linear_Layer_1(features_x)\n",
    "        tanh_op = self.Tanh_Layer(liner1_op)\n",
    "        \n",
    "        # get fastText word embeddings\n",
    "        word_embeds=self.Word_Embeds(word_ids)\n",
    "        \n",
    "        # concat first layer ooutput and fastText word embeddings and feed into second linear layer\n",
    "        features_embed_cat = torch.cat((word_embeds,tanh_op ),dim=1)\n",
    "        \n",
    "        # final softmax layer gives the probability\n",
    "        liner3_op=self.Linear_Layer_3(features_embed_cat)\n",
    "        scores = self.Softmax_Layer(liner3_op)\n",
    "        return scores\n",
    "\n",
    "    def CrossEntropy(self, features, word_ids, gold_labels):\n",
    "        scores= self.get_scores(features, word_ids)\n",
    "        loss = self.loss_fn(scores, gold_labels)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, features, word_ids):\n",
    "        scores= self.get_scores(features, word_ids).data.numpy()\n",
    "        # transform scores into array, if score is larger than 0.5, it is 1; otherwise 0\n",
    "        predictions = [np.argmax(sc) for sc in scores]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" [BERT_NER] Function for training Code Recognizer \"\"\"\n",
    "\n",
    "def train_ctc_model(train_file, test_file):\n",
    "    \n",
    "    # training and test dataset (default)\n",
    "    train_file = parameters_ctc['train_file']\n",
    "    test_file = parameters_ctc['test_file']\n",
    "    \n",
    "    # extract features from two language models trained on Gigaword and StackOverﬂow\n",
    "    features = Features(RESOURCES)\n",
    "    train_tokens, train_features, train_labels = features.get_features(train_file, True)\n",
    "    test_tokens, test_features, test_labels = features.get_features(test_file, False)\n",
    "    \n",
    "    # get pretrained fastText embedding\n",
    "    vocab_size, word_to_id, id_to_word, word_to_vec = get_word_dict_pre_embeds(train_file, test_file)\n",
    "    train_ids, test_ids = get_train_test_word_id(train_file, test_file,  word_to_id)\n",
    "    \n",
    "    # transform each ngram probability into a k-dimensional vector using Gaussian binning\n",
    "    word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (vocab_size, parameters_ctc['word_dim']))\n",
    "    \n",
    "    # reate wordId to fastText embedding map\n",
    "    for word in word_to_vec:\n",
    "        word_embeds[word_to_id[word]]=word_to_vec[word]\n",
    "    \n",
    "    # concatenate the outputs with fastText embedding\n",
    "    ctc_classifier = NeuralClassifier(len(train_features[0]), max(train_labels) + 1, vocab_size, word_embeds)\n",
    "    ctc_classifier.to(device)\n",
    "    \n",
    "    # binary classifier\n",
    "    optimizer = torch.optim.Adam(ctc_classifier.parameters(), lr=parameters_ctc[\"LR\"])\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "    \n",
    "    # prepare dataset\n",
    "    train_x = Variable(torch.FloatTensor(train_features).to(device))\n",
    "    train_x_words = Variable(torch.LongTensor(train_ids).to(device))\n",
    "    train_y = Variable(torch.LongTensor(train_labels).to(device))\n",
    "\n",
    "    test_x = Variable(torch.FloatTensor(test_features).to(device))\n",
    "    test_x_words = Variable(torch.LongTensor(test_ids).to(device))\n",
    "    test_y = Variable(torch.LongTensor(test_labels).to(device))\n",
    "\n",
    "    # training\n",
    "    for epoch in range(parameters_ctc['epochs']):\n",
    "        loss = ctc_classifier.CrossEntropy(train_features, train_x_words, train_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_scores,  train_preds = ctc_classifier(train_features, train_x_words)\n",
    "        test_scores, test_preds = ctc_classifier(test_features, test_x_words)\n",
    "        \n",
    "        eval(test_preds, test_labels, \"test\")\n",
    "\n",
    "    return ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "a3b318fb-6d9a-4f2e-b4fa-1506a27a890d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.428365932464601, 0.19701098799705508, 0.29119153594970726, 0.01899447679519639, 0.002]\n",
      "-------------------- test --------------------\n",
      "P:  54.4444  R: 18.5606  F:  27.6836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       736\n",
      "           1       0.54      0.19      0.28       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.65      0.56      0.56      1000\n",
      "weighted avg       0.71      0.74      0.69      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  89.2857  R: 9.4697  F:  17.1233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       736\n",
      "           1       0.89      0.09      0.17       264\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.82      0.55      0.51      1000\n",
      "weighted avg       0.79      0.76      0.68      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  85.7143  R: 4.5455  F:  8.6331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.86      0.05      0.09       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.80      0.52      0.47      1000\n",
      "weighted avg       0.77      0.75      0.65      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  100.0  R: 2.2727  F:  4.4444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       1.00      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.87      0.51      0.45      1000\n",
      "weighted avg       0.81      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  83.3333  R: 1.8939  F:  3.7037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.83      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.79      0.51      0.44      1000\n",
      "weighted avg       0.76      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  80.0  R: 1.5152  F:  2.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.80      0.02      0.03       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.77      0.51      0.44      1000\n",
      "weighted avg       0.75      0.74      0.63      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  85.7143  R: 2.2727  F:  4.428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.86      0.02      0.04       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.80      0.51      0.45      1000\n",
      "weighted avg       0.77      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  87.5  R: 2.6515  F:  5.1471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.88      0.03      0.05       264\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.81      0.51      0.45      1000\n",
      "weighted avg       0.78      0.74      0.64      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  92.3077  R: 4.5455  F:  8.6643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       736\n",
      "           1       0.92      0.05      0.09       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.83      0.52      0.47      1000\n",
      "weighted avg       0.79      0.75      0.65      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  90.0  R: 6.8182  F:  12.6761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       736\n",
      "           1       0.90      0.07      0.13       264\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.82      0.53      0.49      1000\n",
      "weighted avg       0.79      0.75      0.66      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  92.8571  R: 9.8485  F:  17.8082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       736\n",
      "           1       0.93      0.10      0.18       264\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.84      0.55      0.52      1000\n",
      "weighted avg       0.80      0.76      0.68      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  95.2381  R: 15.1515  F:  26.1438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       736\n",
      "           1       0.95      0.15      0.26       264\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.86      0.57      0.56      1000\n",
      "weighted avg       0.82      0.77      0.71      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  96.2963  R: 19.697  F:  32.7044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87       736\n",
      "           1       0.96      0.20      0.33       264\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.87      0.60      0.60      1000\n",
      "weighted avg       0.83      0.79      0.73      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  89.8551  R: 23.4848  F:  37.2372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87       736\n",
      "           1       0.90      0.23      0.37       264\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.84      0.61      0.62      1000\n",
      "weighted avg       0.81      0.79      0.74      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  81.9149  R: 29.1667  F:  43.0168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88       736\n",
      "           1       0.82      0.29      0.43       264\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.81      0.63      0.65      1000\n",
      "weighted avg       0.80      0.80      0.76      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  80.3279  R: 37.1212  F:  50.7772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       736\n",
      "           1       0.80      0.37      0.51       264\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.67      0.70      1000\n",
      "weighted avg       0.81      0.81      0.78      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.7671  R: 43.5606  F:  56.0976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       736\n",
      "           1       0.79      0.44      0.56       264\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.81      0.70      0.72      1000\n",
      "weighted avg       0.82      0.82      0.80      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.8786  R: 50.3788  F:  60.8696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       736\n",
      "           1       0.77      0.50      0.61       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.81      0.72      0.75      1000\n",
      "weighted avg       0.82      0.83      0.82      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  73.7624  R: 56.4394  F:  63.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       736\n",
      "           1       0.74      0.56      0.64       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.80      0.75      0.76      1000\n",
      "weighted avg       0.82      0.83      0.82      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.875  R: 60.9848  F:  65.9836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       736\n",
      "           1       0.72      0.61      0.66       264\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.79      0.76      0.78      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.0833  R: 65.5303  F:  68.6508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       736\n",
      "           1       0.72      0.66      0.69       264\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.80      0.78      0.79      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.1569  R: 69.697  F:  70.9056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       736\n",
      "           1       0.72      0.70      0.71       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.80      0.80      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.3208  R: 71.5909  F:  71.4556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       736\n",
      "           1       0.71      0.72      0.71       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.4801  R: 75.0  F:  73.1978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       736\n",
      "           1       0.71      0.75      0.73       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.82      0.82      1000\n",
      "weighted avg       0.86      0.85      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0247  R: 76.1364  F:  73.4918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       736\n",
      "           1       0.71      0.76      0.73       264\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.81      0.82      0.82      1000\n",
      "weighted avg       0.86      0.85      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0345  R: 78.0303  F:  74.3682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       736\n",
      "           1       0.71      0.78      0.74       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.83      0.82      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.9898  R: 78.7879  F:  74.6858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.71      0.79      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.8475  R: 79.1667  F:  74.7764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.71      0.79      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.3333  R: 79.9242  F:  74.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       736\n",
      "           1       0.70      0.80      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.84      0.82      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.1987  R: 80.303  F:  74.9117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.70      0.80      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.84      0.83      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  70.7641  R: 80.6818  F:  75.3982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.75       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.84      0.83      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.0963  R: 81.0606  F:  75.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       736\n",
      "           1       0.71      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  71.5719  R: 81.0606  F:  76.0213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       736\n",
      "           1       0.72      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.85      0.83      1000\n",
      "weighted avg       0.87      0.86      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  72.2973  R: 81.0606  F:  76.4286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       736\n",
      "           1       0.72      0.81      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  72.5086  R: 79.9242  F:  76.036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       736\n",
      "           1       0.73      0.80      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.83      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  73.2639  R: 79.9242  F:  76.4493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       736\n",
      "           1       0.73      0.80      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  73.6842  R: 79.5455  F:  76.5027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.80      0.77       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.1135  R: 79.1667  F:  76.5568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.88      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.0214  R: 78.7879  F:  76.3303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.84      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  74.2857  R: 78.7879  F:  76.4706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       736\n",
      "           1       0.74      0.79      0.76       264\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  75.6364  R: 78.7879  F:  77.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  75.9124  R: 78.7879  F:  77.3234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.79      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.3838  R: 78.4091  F:  77.3832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.4925  R: 77.6515  F:  77.0677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       736\n",
      "           1       0.76      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  76.779  R: 77.6515  F:  77.2128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.77       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.84      0.85      0.84      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3585  R: 77.6515  F:  77.5047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.4436  R: 78.0303  F:  77.7358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.2388  R: 78.4091  F:  77.8195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.77      0.78      0.78       264\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.2772  R: 79.1667  F:  78.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.2772  R: 79.1667  F:  78.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.6952  R: 79.1667  F:  78.424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       736\n",
      "           1       0.78      0.79      0.78       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.85      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.022  R: 80.6818  F:  79.3296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.4194  R: 81.8182  F:  79.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.82      0.80       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.87      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.0609  R: 81.4394  F:  79.1897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3381  R: 81.4394  F:  79.3358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.2563  R: 81.0606  F:  79.1128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       736\n",
      "           1       0.77      0.81      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3723  R: 80.303  F:  78.8104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.77      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.3723  R: 80.303  F:  78.8104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.77      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.5735  R: 79.9242  F:  78.7313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.85      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  77.8598  R: 79.9242  F:  78.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.1481  R: 79.9242  F:  79.0262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------- test --------------------\n",
      "P:  78.4387  R: 79.9242  F:  79.1745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       736\n",
      "           1       0.78      0.80      0.79       264\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train Code Recognizer \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/BERT_NER/')\n",
    "\n",
    "from utils_ctc import *\n",
    "from utils_ctc.prediction_ctc import *\n",
    "\n",
    "# training dataset & test dataset\n",
    "train_file = parameters_ctc['train_file']\n",
    "test_file = parameters_ctc['test_file']\n",
    "\n",
    "# train the Code Recognizer\n",
    "ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features = train_ctc_model(train_file, test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of code recognizer\n",
    "From the training results above, our Code Recognizer model achieves the precision of 78.44, the recall of 79.92, and the $F_1$ scores of 79.14. Our reproduce results show that the recall and $F_1$ scores are slightly worse than the paper; yet, this may result from the fact that we have limited computing powers, so we train with less epoches. To sum, our results are mostly consistent with the original result from the author.\n",
    "\n",
    "![paperCodeRecogizer](./notebook_resources/paperCodeRecogizer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceF_grl6CSPB",
    "nbpresent": {
     "id": "fc9a1a00-1e64-4ea7-ab87-fd5c8b7ce5e9"
    }
   },
   "source": [
    "### Entity segmentation (Entity Segmenter)\n",
    "\n",
    "The segmentation task refers to identifying entity spans without assigning entity category. **This is a binary classifier.** The Entity Segmenter model trained on the annotated StackOverﬂow corpus that can achieve 90.41% precision on the validation dataset. The Entity Segmenter concatenates with two hand-crafted features:\n",
    "\n",
    "- **Word frequency**, which represents the word occurrence count in the training set. In the given StackOverflow corpus, code and non-code have an average frequency of 1.47 and 7.41. An ambiguous token that can be either code or non-code entities, such as \"windows\", have a much higher average frequency of 92.57.\n",
    "\n",
    "- **Code markdown**, which indicates whether the given token appears inside a `⟨code⟩` markdown in the StackOverflow post. This is noisy as users do not always enclose inline code in a `⟨code⟩` tag or sometimes use the tag to highlight non-code texts.\n",
    "\n",
    "\n",
    "The segmentation model follows the simple BERT fine-tuning architecture except for the input, where BERT embeddings are concatenated with 100-dimensional code markdown and 10-dimensional word frequency features. \n",
    "\n",
    "**Noted that** some essential files (such as word frequency) and the pretrained model are missing in the folder provided by the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtuFvnA3CUzA",
    "nbpresent": {
     "id": "24e48ef2-8827-45fb-b019-2978d68d4511"
    }
   },
   "source": [
    "### Embedding-Level Attention\n",
    "\n",
    "For each word $w_i$, there are 3 embeddings \n",
    "- BERT ($w_{i1}$)\n",
    "- Code recognizer ($w_{i2}$)\n",
    "- Entity Segmenter ($w_{i3}$)\n",
    "\n",
    "The embedding-level attention $\\alpha_{it}$ ($t \\in \\{1, 2, 3\\}$) captures the word's contribution to the meaning of the word.\n",
    "\n",
    "To compute $\\alpha_{it}$, we pass the input embeddings through a bidirectional GRU and generate their corresponding hidden representations $h_{it} = \\vec{GRU}(w_{it})$\n",
    "\n",
    "These vectors are then passed through a non-linear layer, which outputs $u_{it} = tanh(W_e h_{it} + b_e)$.\n",
    "\n",
    "$u_e$: randomly initialized and updated during the training process.\n",
    "\n",
    "This context vector is combined with the hidden embedding representation using a softmax function to extract weight of the embeddings:\n",
    "$$\n",
    "  \\alpha_{it} = \\frac{\\exp{u_{it}^T u_e}}{\\sum_t \\exp{u_{it}^T u_e}}\n",
    "$$\n",
    "\n",
    "Finally, we create the word vector by a weighted sum of all the information from different embeddings as \n",
    "$$\n",
    "  word_i = \\sum_t \\alpha_{it}h_{it}\n",
    "$$\n",
    "\n",
    "\n",
    "![embeding](./notebook_resources/embeddingLevel.png)\n",
    "\n",
    "The result is then fed into a linear-CRF layer, which predicts the entity category for each word based the BIO tagging schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Embedded level attention described above; see forward() for more details \"\"\"\n",
    "\n",
    "class Embedded_Attention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Embedded_Attention, self).__init__()\n",
    "    self.max_len = 3\n",
    "    self.input_dim = 1824\n",
    "    self.hidden_dim = 150\n",
    "    self.bidirectional = True\n",
    "    self.drop_out_rate = 0.5 \n",
    "    self.context_vector_size = [parameters['embedding_context_vecotr_size'], 1]\n",
    "    self.drop = nn.Dropout(p=self.drop_out_rate)\n",
    "    self.word_GRU = nn.GRU(input_size=self.input_dim, \n",
    "                           hidden_size=self.hidden_dim,\n",
    "                           bidirectional=self.bidirectional,\n",
    "                           batch_first=True)\n",
    "    self.w_proj = nn.Linear(in_features=2*self.hidden_dim ,out_features=2*self.hidden_dim)\n",
    "    self.w_context_vector = nn.Parameter(torch.randn(self.context_vector_size).float())\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    init_gru(self.word_GRU)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # h_it = GRU(w_it)\n",
    "    x, _ = self.word_GRU(x)\n",
    "    # u_it = tanh(w*h_it + b)\n",
    "    Hw = torch.tanh(self.w_proj(x))\n",
    "    # softmax function that output the weights for each word embeddings\n",
    "    w_score = self.softmax(Hw.matmul(self.w_context_vector))\n",
    "    x = x.mul(w_score)\n",
    "    x = torch.sum(x, dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftNER Model\n",
    "\n",
    "The code below is the `SoftNER` model, which is described above, proposed by the author. The main forwarding logic is implemented at `_get_lstm_features_w_elmo()`. The author implements different base models, but writes code only one time by using several configurations, such as `use_elmo`, details is listed below; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model\n",
    "- BiLSTM-CRF (ELMoVerflow): same model as SoftNER, but with `use_han = False` and `use_elmo = True`\n",
    "- Attentive BiLSTM-CRF (ELMoVerflow): same model as SoftNER, but with `use_elmo = True`\n",
    "- Fine-tuned out-of-domain BERT: use the off-the-shelf BERT trained on normal web texts instead of StackOverflow code texts\n",
    "- Fine-tuned BERTOverflow: same model as SoftNER, but with `use_han = False`. \n",
    "- SoftNER\n",
    "\n",
    "[BERT model checkpoints](https://drive.google.com/drive/folders/1z4zXexpYU10QNlpcSA_UPfMb2V34zHHO) can be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model configuration\n",
    "\n",
    "- `LR`: learning rate\n",
    "- `epochs`: number of epochs to train\n",
    "- `lower`: lowercase all inputs\n",
    "- `zeros`: replace all digits by 0\n",
    "- `char_dim`: Character embedding dimension\n",
    "- `char_lstm_dim`: Char LSTM hidden layer size\n",
    "- `char_bidirect`: Use bidirectional LSTM for chars\n",
    "- `word_dim`: Token embedding dimension\n",
    "- `word_lstm_dim`: Token LSTM hidden layer size\n",
    "- `word_bidirect`: Use bidirectional LSTM for words\n",
    "- `dropout`: Droupout on the input\n",
    "- `char_mode`: char_CNN or char_LSTM\n",
    "- `use_elmo`: whether or not to ues elmo\n",
    "- `use_elmo_w_char`: whether or not to ues elmo with char embeds\n",
    "- `use_freq_vector`: whether or not to ues the word frequency\n",
    "- `freq_mapper_bin_count`: how many bins to use in gaussian binning of the frequency vector\n",
    "- `freq_mapper_bin_width`: the width of each bin for the gaussian binning of the frequency vector\n",
    "- `use_segmentation_vector`: whether or not to ues the code_pred vector\n",
    "- `use_han`: whether or not to ues Hierarchical Attention Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "07b39fd9-d60b-4623-9246-e672f9cd3979"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, freq_embed_dim, \n",
    "                 seg_pred_embed_dim, hidden_dim, char_lstm_dim=25,\n",
    "                 char_to_ix=None, pre_word_embeds=None, word_freq_embeds=None, word_ner_pred_embeds=None, \n",
    "                 word_seg_pred_embeds=None, word_markdown_embeds=None, word_ctc_pred_embeds=None, char_embedding_dim=25, use_gpu=False,\n",
    "                 n_cap=None, cap_embedding_dim=None, use_crf=True, char_mode='CNN'):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.n_cap = n_cap\n",
    "        self.cap_embedding_dim = cap_embedding_dim\n",
    "        self.use_crf = use_crf\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.out_channels = char_lstm_dim\n",
    "        self.char_mode = char_mode\n",
    "        self.embed_attn = Embedded_Attention()\n",
    "        self.word_attn = Word_Attn()        \n",
    "        self.use_elmo = parameters['use_elmo']\n",
    "\n",
    "        if self.use_elmo:\n",
    "            options_file = parameters[\"elmo_options\"]\n",
    "            weight_file = parameters[\"elmo_weight\"]\n",
    "\n",
    "            self.elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "            self.elmo_2 = ElmoEmbedder(options_file, weight_file)\n",
    "        \n",
    "        print('char_mode: %s, out_channels: %d, hidden_dim: %d, ' % (char_mode, char_lstm_dim, hidden_dim))\n",
    "        if parameters['use_han']:\n",
    "            self.lstm=nn.LSTM(300, hidden_dim, bidirectional=True)\n",
    "        else:\n",
    "            self.lstm=nn.LSTM(1824, hidden_dim, bidirectional=True)\n",
    "        \n",
    "        if self.use_elmo:\n",
    "            if parameters['use_elmo_w_char']:\n",
    "                if self.n_cap and self.cap_embedding_dim:\n",
    "                    self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "                    init_embedding(self.cap_embeds.weight)\n",
    "\n",
    "                if char_embedding_dim is not None:\n",
    "                    self.char_lstm_dim = char_lstm_dim\n",
    "                    self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "                    init_embedding(self.char_embeds.weight)\n",
    "\n",
    "                    if self.char_mode == 'LSTM':\n",
    "                        self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                        init_lstm(self.char_lstm)\n",
    "                    if self.char_mode == 'CNN':\n",
    "                        self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "        else:\n",
    "            if self.n_cap and self.cap_embedding_dim:\n",
    "                self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "                init_embedding(self.cap_embeds.weight)\n",
    "\n",
    "            if char_embedding_dim is not None:\n",
    "                self.char_lstm_dim = char_lstm_dim\n",
    "                self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "                init_embedding(self.char_embeds.weight)\n",
    "                \n",
    "                if self.char_mode == 'LSTM':\n",
    "                    self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                    init_lstm(self.char_lstm)\n",
    "                if self.char_mode == 'CNN':\n",
    "                    self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "\n",
    "            self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "            if pre_word_embeds is not None:\n",
    "                self.pre_word_embeds = True\n",
    "                self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "            else:\n",
    "                self.pre_word_embeds = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(parameters['dropout'])\n",
    "\n",
    "        #----------adding frequency embedding--------\n",
    "        self.freq_embeds = nn.Embedding(vocab_size, freq_embed_dim)\n",
    "        if word_freq_embeds is not None:\n",
    "            self.word_freq_embeds = True\n",
    "            self.freq_embeds.weight = nn.Parameter(torch.FloatTensor(word_freq_embeds))\n",
    "        else:\n",
    "            self.word_freq_embeds = False\n",
    "        \n",
    "        #----------adding segmentation embedding--------\n",
    "        self.seg_embeds = nn.Embedding(parameters['segmentation_count'], parameters['segmentation_dim'])\n",
    "        if word_seg_pred_embeds is not None:\n",
    "            self.use_seg_pred_embed = True\n",
    "            self.seg_embeds.weight = nn.Parameter(torch.FloatTensor(word_seg_pred_embeds))\n",
    "        else:\n",
    "            self.use_seg_pred_embed = False\n",
    "        \n",
    "        #----------adding ctc prediction embedding (code recognizer)--------\n",
    "        self.ctc_pred_embeds = nn.Embedding(parameters['code_recognizer_count'], parameters['code_recognizer_dim'])\n",
    "        if word_ctc_pred_embeds is not None:\n",
    "            self.use_ctc_pred_embed = True\n",
    "            self.ctc_pred_embeds.weight = nn.Parameter(torch.FloatTensor(word_ctc_pred_embeds))\n",
    "        else:\n",
    "            self.use_ctc_pred_embed = False\n",
    "        \n",
    "        init_lstm(self.lstm)\n",
    "        self.hw_trans = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.hw_gate = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.h2_h1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
    "        init_linear(self.h2_h1)\n",
    "        init_linear(self.hidden2tag)\n",
    "        init_linear(self.hw_gate)\n",
    "        init_linear(self.hw_trans)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.transitions = nn.Parameter(\n",
    "                torch.zeros(self.tagset_size, self.tagset_size))\n",
    "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "    \n",
    "    # apply attention architecture to the model\n",
    "    def apply_attention(self, elmo_embeds, seg_embeds, ctc_embeds):\n",
    "        word_tensor_list = []\n",
    "        word_pos_list=[]\n",
    "        sent_len =elmo_embeds.size()[0]\n",
    "\n",
    "        for index in range(sent_len):\n",
    "            elmo_rep = elmo_embeds[index]\n",
    "            ctc_rep = ctc_embeds[index]\n",
    "            seg_rep = seg_embeds[index]\n",
    "            comb_rep = torch.cat((elmo_rep, ctc_rep, seg_rep)).view(1, 1, -1)\n",
    "            attentive_rep=self.embed_attn(comb_rep)\n",
    "            word_tensor_list.append(attentive_rep)\n",
    "            word_pos_list.append(index+1)\n",
    "\n",
    "        word_tensor =  torch.stack(word_tensor_list)\n",
    "        if self.use_gpu:\n",
    "            word_tensor=word_tensor.cuda()\n",
    "        \n",
    "        x = _align_word(word_tensor, word_pos_list)\n",
    "        if self.use_gpu:\n",
    "            x=x.cuda()\n",
    "        y = self.word_attn(x)\n",
    "        return y\n",
    "\n",
    "    # main forwarding logic\n",
    "    def _get_lstm_features_w_elmo(self, sentence_words, sentence, seg_pred, ctc_pred):\n",
    "        character_ids = batch_to_ids([sentence_words])\n",
    "        if self.use_gpu:\n",
    "            character_ids = character_ids.cuda()\n",
    "        embeddings = self.elmo(character_ids)\n",
    "        embeddings = embeddings['elmo_representations'][0]\n",
    "        embeds = embeddings[0]\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            embeds=embeds.cuda()\n",
    "            elmo_embeds=embeds.cuda()\n",
    "        else:\n",
    "            elmo_embeds=embeds\n",
    "        # if the model should use word frequency as domain-specific input representation\n",
    "        if parameters['use_freq_vector']:\n",
    "            frequency_embeddings = self.freq_embeds(sentence)\n",
    "            embeds = torch.cat((embeds, frequency_embeddings), 0)\n",
    "        # if the model should use entity segmenter as domain-specific input representation\n",
    "        if parameters['use_segmentation_vector'] :\n",
    "            segment_embeddings = self.seg_embeds(seg_pred)\n",
    "            embeds = torch.cat((embeds, segment_embeddings), 1)\n",
    "        # if the model should use code recognizer as domain-specific input representation\n",
    "        if parameters['use_code_recognizer_vector']:\n",
    "            ctc_pred_embeddings = self.ctc_pred_embeds(ctc_pred)\n",
    "            embeds = torch.cat((embeds, ctc_pred_embeddings), 1)\n",
    "        # if the model should apply the hierarchical Attention Network\n",
    "        if parameters['use_han']:\n",
    "            attentive_word_embeds = self.apply_attention(elmo_embeds, segment_embeddings, ctc_pred_embeddings)\n",
    "            embeds=attentive_word_embeds\n",
    "        else:\n",
    "            embeds = embeds.unsqueeze(1)\n",
    "        \n",
    "        embeds = self.dropout(embeds)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = lstm_out.view(len(sentence_words), self.hidden_dim*2)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        # analogous to forward\n",
    "        init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0.0\n",
    "        forward_var = Variable(init_vvars)\n",
    "        if self.use_gpu:\n",
    "            forward_var = forward_var.cuda()\n",
    "        for feat in feats:\n",
    "            next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
    "            _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
    "            bptrs_t = bptrs_t.squeeze().data.cpu().numpy()\n",
    "            next_tag_var = next_tag_var.data.cpu().numpy()\n",
    "            viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t]\n",
    "            viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
    "            if self.use_gpu:\n",
    "                viterbivars_t = viterbivars_t.cuda()\n",
    "            forward_var = viterbivars_t + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
    "        terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
    "        best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
    "        path_score = terminal_var[best_tag_id]\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def forward(self,sentence_tokens, sentence, sentence_seg_preds, sentence_ctc_preds, chars, caps, chars2_length, d):\n",
    "        feats = self._get_lstm_features_w_elmo(sentence_tokens, sentence, sentence_seg_preds, sentence_ctc_preds)\n",
    "        if self.use_crf:\n",
    "            score, tag_seq = self.viterbi_decode(feats)\n",
    "        else:\n",
    "            score, tag_seq = torch.max(feats, 1)\n",
    "            tag_seq = list(tag_seq.cpu().data)\n",
    "\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result & Evaluation\n",
    "\n",
    "As of today, some essential files for entity segmenter are still missing, so we can not reproduce complete results in the paper. We have contacted the author several times, and thanks to her help so we can receive several missing files, such as the pre-trained FastText model, word frequency files, and config files for transformers. However, upon until now, we have not received the files that are required by the entity segmenter module. Thus, we can only show the prediction result found from the Github repository. The details are listed below.\n",
    "\n",
    "![dataset](./notebook_resources/dataset.png)\n",
    "\n",
    "Fortunately, the author saved the predictions on the dataset with two auxiliary models, so we can still train the SoftNER model on those datasets. Epochs of 100 are required for training the SoftNER model, and each epoch costs more than 4 hours on our server. Hence, we only trained 3 epochs to observe the results.\n",
    "\n",
    "The training log and the results for each epoch are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: ignoring input\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "completed ctc predictions reading \r\n",
      "set of entities:  ['Class', 'Application', 'Variable', 'User_Interface_Element', 'Code_Block', 'Function', 'Language', 'Library', 'Value', 'Data_Structure', 'Data_Type', 'File_Type', 'File_Name', 'Version', 'HTML_XML_Tag', 'Device', 'Operating_System', 'Website', 'Algorithm']\r\n",
      "------------------------------------------------------------\r\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  741\r\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  897\r\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/train_merged_labels.txt  :  9263\r\n",
      "Number of sentences after merging :  9263\r\n",
      "Max len sentences has 92 words\r\n",
      "------------------------------------------------------------\r\n",
      "------------------------------------------------------------\r\n",
      "Number of questions in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  249\r\n",
      "Number of answers in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  315\r\n",
      "Number of sentences in  ../../resources/annotated_ner_data/StackOverflow/test_merged_labels.txt  :  3108\r\n",
      "Number of sentences after merging :  3108\r\n",
      "Max len sentences has 83 words\r\n",
      "------------------------------------------------------------\r\n",
      "Found 3294 unique words (136996 in total)\r\n",
      "Found 108 unique characters\r\n",
      "Found 41 unique named entity tags\r\n",
      "char_mode: CNN, out_channels: 25, hidden_dim: 300, \r\n",
      "---------epoch count:  1\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11118 phrases; correct: 8416.\r\n",
      "accuracy:  97.66%; precision:  75.70%; recall:  75.14%; FB1:  75.42\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  0\r\n",
      "      Application: precision:  83.91%; recall:  80.35%; FB1:  82.09 foundGuessed:  1243\r\n",
      "            Class: precision:  71.78%; recall:  78.51%; FB1:  74.99 foundGuessed:  1481\r\n",
      "       Code_Block: precision:  72.17%; recall:  60.00%; FB1:  65.53 foundGuessed:  690\r\n",
      "   Data_Structure: precision:  77.19%; recall:  88.66%; FB1:  82.53 foundGuessed:  719\r\n",
      "        Data_Type: precision:  79.50%; recall:  84.45%; FB1:  81.90 foundGuessed:  444\r\n",
      "           Device: precision:  59.31%; recall:  43.22%; FB1:  50.00 foundGuessed:  145\r\n",
      "        File_Name: precision:  75.78%; recall:  82.87%; FB1:  79.17 foundGuessed:  351\r\n",
      "        File_Type: precision:  98.70%; recall:  41.42%; FB1:  58.35 foundGuessed:  154\r\n",
      "         Function: precision:  79.84%; recall:  77.08%; FB1:  78.44 foundGuessed:  754\r\n",
      "     HTML_XML_Tag: precision:  83.61%; recall:  49.51%; FB1:  62.20 foundGuessed:  122\r\n",
      "         Language: precision:  77.53%; recall:  94.70%; FB1:  85.26 foundGuessed:  899\r\n",
      "          Library: precision:  69.68%; recall:  73.37%; FB1:  71.48 foundGuessed:  775\r\n",
      " Operating_System: precision:  85.07%; recall:  33.33%; FB1:  47.90 foundGuessed:  67\r\n",
      "User_Interface_Element: precision:  84.86%; recall:  81.76%; FB1:  83.28 foundGuessed:  898\r\n",
      "            Value: precision:  88.99%; recall:  68.14%; FB1:  77.18 foundGuessed:  536\r\n",
      "         Variable: precision:  62.60%; recall:  80.46%; FB1:  70.41 foundGuessed:  1441\r\n",
      "          Version: precision:  94.30%; recall:  70.82%; FB1:  80.89 foundGuessed:  193\r\n",
      "          Website: precision:  38.35%; recall:  74.53%; FB1:  50.64 foundGuessed:  206\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3838 phrases; correct: 2709.\r\n",
      "accuracy:  97.14%; precision:  70.58%; recall:  70.22%; FB1:  70.40\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  0\r\n",
      "      Application: precision:  73.62%; recall:  75.43%; FB1:  74.51 foundGuessed:  417\r\n",
      "            Class: precision:  67.24%; recall:  76.47%; FB1:  71.56 foundGuessed:  580\r\n",
      "       Code_Block: precision:  67.43%; recall:  58.28%; FB1:  62.52 foundGuessed:  261\r\n",
      "   Data_Structure: precision:  84.41%; recall:  89.88%; FB1:  87.06 foundGuessed:  263\r\n",
      "        Data_Type: precision:  84.21%; recall:  86.49%; FB1:  85.33 foundGuessed:  114\r\n",
      "           Device: precision:  51.43%; recall:  33.96%; FB1:  40.91 foundGuessed:  35\r\n",
      "        File_Name: precision:  80.77%; recall:  77.30%; FB1:  79.00 foundGuessed:  156\r\n",
      "        File_Type: precision:  93.33%; recall:  32.56%; FB1:  48.28 foundGuessed:  45\r\n",
      "         Function: precision:  72.57%; recall:  61.65%; FB1:  66.67 foundGuessed:  226\r\n",
      "     HTML_XML_Tag: precision:  61.29%; recall:  36.54%; FB1:  45.78 foundGuessed:  31\r\n",
      "         Language: precision:  69.55%; recall:  85.96%; FB1:  76.88 foundGuessed:  220\r\n",
      "          Library: precision:  65.66%; recall:  67.70%; FB1:  66.67 foundGuessed:  265\r\n",
      " Operating_System: precision:  91.18%; recall:  46.97%; FB1:  62.00 foundGuessed:  34\r\n",
      "User_Interface_Element: precision:  77.05%; recall:  79.44%; FB1:  78.22 foundGuessed:  366\r\n",
      "            Value: precision:  87.26%; recall:  62.84%; FB1:  73.07 foundGuessed:  157\r\n",
      "         Variable: precision:  53.92%; recall:  72.75%; FB1:  61.94 foundGuessed:  510\r\n",
      "          Version: precision:  87.50%; recall:  69.37%; FB1:  77.39 foundGuessed:  88\r\n",
      "          Website: precision:  28.57%; recall:  51.28%; FB1:  36.70 foundGuessed:  70\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\\begin{table}[htbp]\r\n",
      "\\centering\r\n",
      "\\begin{tabular}{|c|c|c|c|}\r\n",
      "\\hline\r\n",
      " & Precision & Recall & F1\\\\\r\n",
      "\\hline\r\n",
      "Class & 67.24 & 76.47 & 71.56\\\\\r\n",
      "Application & 73.62 & 75.43 & 74.51\\\\\r\n",
      "Variable & 53.92 & 72.75 & 61.94\\\\\r\n",
      "User Interface Element & 77.05 & 79.44 & 78.22\\\\\r\n",
      "Code Block & 67.43 & 58.28 & 62.52\\\\\r\n",
      "Function & 72.57 & 61.65 & 66.67\\\\\r\n",
      "Language & 69.55 & 85.96 & 76.88\\\\\r\n",
      "Library & 65.66 & 67.7 & 66.67\\\\\r\n",
      "Value & 87.26 & 62.84 & 73.07\\\\\r\n",
      "Data Structure & 84.41 & 89.88 & 87.06\\\\\r\n",
      "Data Type & 84.21 & 86.49 & 85.33\\\\\r\n",
      "File Type & 93.33 & 32.56 & 48.28\\\\\r\n",
      "File Name & 80.77 & 77.3 & 79.0\\\\\r\n",
      "Version & 87.5 & 69.37 & 77.39\\\\\r\n",
      "HTML XML Tag & 61.29 & 36.54 & 45.78\\\\\r\n",
      "Device & 51.43 & 33.96 & 40.91\\\\\r\n",
      "Operating System & 91.18 & 46.97 & 62.0\\\\\r\n",
      "Website & 28.57 & 51.28 & 36.7\\\\\r\n",
      "Algorithm & 0 & 0.0 & 0\\\\\r\n",
      "overall & 70.58 & 70.22 & 70.4\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  21775.404473781586 secs\r\n",
      "---------epoch count:  2\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11144 phrases; correct: 9226.\r\n",
      "accuracy:  98.35%; precision:  82.79%; recall:  82.38%; FB1:  82.58\r\n",
      "        Algorithm: precision:  83.33%; recall:  12.20%; FB1:  21.28 foundGuessed:  6\r\n",
      "      Application: precision:  81.43%; recall:  89.21%; FB1:  85.15 foundGuessed:  1422\r\n",
      "            Class: precision:  84.33%; recall:  73.93%; FB1:  78.79 foundGuessed:  1187\r\n",
      "       Code_Block: precision:  74.84%; recall:  69.88%; FB1:  72.27 foundGuessed:  775\r\n",
      "   Data_Structure: precision:  75.16%; recall:  94.25%; FB1:  83.63 foundGuessed:  785\r\n",
      "        Data_Type: precision:  87.97%; recall:  89.23%; FB1:  88.60 foundGuessed:  424\r\n",
      "           Device: precision:  90.91%; recall:  75.38%; FB1:  82.42 foundGuessed:  165\r\n",
      "        File_Name: precision:  86.14%; recall:  89.10%; FB1:  87.60 foundGuessed:  332\r\n",
      "        File_Type: precision:  91.24%; recall:  82.29%; FB1:  86.53 foundGuessed:  331\r\n",
      "         Function: precision:  80.15%; recall:  84.25%; FB1:  82.15 foundGuessed:  821\r\n",
      "     HTML_XML_Tag: precision:  78.45%; recall:  68.93%; FB1:  73.39 foundGuessed:  181\r\n",
      "         Language: precision:  90.18%; recall:  96.06%; FB1:  93.03 foundGuessed:  784\r\n",
      "          Library: precision:  82.67%; recall:  73.23%; FB1:  77.67 foundGuessed:  652\r\n",
      " Operating_System: precision:  82.53%; recall:  80.12%; FB1:  81.31 foundGuessed:  166\r\n",
      "User_Interface_Element: precision:  92.58%; recall:  81.65%; FB1:  86.77 foundGuessed:  822\r\n",
      "            Value: precision:  88.64%; recall:  79.14%; FB1:  83.62 foundGuessed:  625\r\n",
      "         Variable: precision:  74.07%; recall:  86.62%; FB1:  79.85 foundGuessed:  1311\r\n",
      "          Version: precision:  88.26%; recall:  90.66%; FB1:  89.44 foundGuessed:  264\r\n",
      "          Website: precision:  86.81%; recall:  74.53%; FB1:  80.20 foundGuessed:  91\r\n",
      "-----------------------------------sh: 1: ./evaluation/conlleval: Permission denied\r\n",
      "\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3851 phrases; correct: 2886.\r\n",
      "accuracy:  97.59%; precision:  74.94%; recall:  74.81%; FB1:  74.87\r\n",
      "        Algorithm: precision:   0.00%; recall:   0.00%; FB1:   0.00 foundGuessed:  1\r\n",
      "      Application: precision:  72.44%; recall:  85.26%; FB1:  78.33 foundGuessed:  479\r\n",
      "            Class: precision:  77.07%; recall:  69.22%; FB1:  72.93 foundGuessed:  458\r\n",
      "       Code_Block: precision:  62.50%; recall:  62.91%; FB1:  62.71 foundGuessed:  304\r\n",
      "   Data_Structure: precision:  77.89%; recall:  92.71%; FB1:  84.66 foundGuessed:  294\r\n",
      "        Data_Type: precision:  88.89%; recall:  86.49%; FB1:  87.67 foundGuessed:  108\r\n",
      "           Device: precision:  73.47%; recall:  67.92%; FB1:  70.59 foundGuessed:  49\r\n",
      "        File_Name: precision:  91.61%; recall:  80.37%; FB1:  85.62 foundGuessed:  143\r\n",
      "        File_Type: precision:  91.92%; recall:  70.54%; FB1:  79.82 foundGuessed:  99\r\n",
      "         Function: precision:  68.29%; recall:  73.68%; FB1:  70.89 foundGuessed:  287\r\n",
      "     HTML_XML_Tag: precision:  68.29%; recall:  53.85%; FB1:  60.22 foundGuessed:  41\r\n",
      "         Language: precision:  81.58%; recall:  87.08%; FB1:  84.24 foundGuessed:  190\r\n",
      "          Library: precision:  70.04%; recall:  64.59%; FB1:  67.21 foundGuessed:  237\r\n",
      " Operating_System: precision:  92.19%; recall:  89.39%; FB1:  90.77 foundGuessed:  64\r\n",
      "User_Interface_Element: precision:  84.91%; recall:  76.06%; FB1:  80.24 foundGuessed:  318\r\n",
      "            Value: precision:  83.15%; recall:  67.89%; FB1:  74.75 foundGuessed:  178\r\n",
      "         Variable: precision:  60.09%; recall:  73.28%; FB1:  66.03 foundGuessed:  461\r\n",
      "          Version: precision:  82.05%; recall:  86.49%; FB1:  84.21 foundGuessed:  117\r\n",
      "          Website: precision:  78.26%; recall:  46.15%; FB1:  58.06 foundGuessed:  23\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_so.py\", line 646, in <module>\r\n",
      "    train_model(model, step_lr_scheduler, optimizer, train_data, dev_data, test_data)\r\n",
      "  File \"train_so.py\", line 541, in train_model\r\n",
      "    best_dev_F, new_dev_F, save = evaluating(model, dev_data, best_dev_F, epoch, phase_name) \r\n",
      "  File \"train_so.py\", line 396, in evaluating\r\n",
      "    print_result.print_result(eval_result, epoch_count, parameters[\"sorted_entity_list_file_name\"], parameters[\"entity_category_code\"], parameters[\"entity_category_human_language\"])\r\n",
      "  File \"/root/Project/StackOverflowNER/code/Attentive_BiLSTM/print_result.py\", line 17, in print_result\r\n",
      "    with open(sorted_entity_list_file) as f:\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'sorted_entity_list_by_count_all.json'\r\n",
      ".59\\\\\r\n",
      "Operating System & 92.19 & 89.39 & 90.77\\\\\r\n",
      "Website & 78.26 & 46.15 & 58.06\\\\\r\n",
      "Algorithm & 0.0 & 0.0 & 0\\\\\r\n",
      "overall & 74.94 & 74.81 & 74.87\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  15856.095844984055 secs\r\n",
      "---------epoch count:  3\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  train\r\n",
      "-----------------------------------\r\n",
      "processed 136996 tokens with 11200 phrases; found: 11093 phrases; correct: 9688.\r\n",
      "accuracy:  98.76%; precision:  87.33%; recall:  86.50%; FB1:  86.92\r\n",
      "        Algorithm: precision:  80.95%; recall:  41.46%; FB1:  54.84 foundGuessed:  21\r\n",
      "      Application: precision:  82.34%; recall:  93.07%; FB1:  87.38 foundGuessed:  1467\r\n",
      "            Class: precision:  83.71%; recall:  84.27%; FB1:  83.99 foundGuessed:  1363\r\n",
      "       Code_Block: precision:  79.26%; recall:  80.12%; FB1:  79.69 foundGuessed:  839\r\n",
      "   Data_Structure: precision:  85.74%; recall:  93.13%; FB1:  89.28 foundGuessed:  680\r\n",
      "        Data_Type: precision:  92.24%; recall:  93.78%; FB1:  93.00 foundGuessed:  425\r\n",
      "           Device: precision:  91.67%; recall:  82.91%; FB1:  87.07 foundGuessed:  180\r\n",
      "        File_Name: precision:  91.77%; recall:  93.77%; FB1:  92.76 foundGuessed:  328\r\n",
      "        File_Type: precision:  89.81%; recall:  91.28%; FB1:  90.54 foundGuessed:  373\r\n",
      "         Function: precision:  87.82%; recall:  83.99%; FB1:  85.86 foundGuessed:  747\r\n",
      "     HTML_XML_Tag: precision:  94.94%; recall:  72.82%; FB1:  82.42 foundGuessed:  158\r\n",
      "         Language: precision:  96.19%; recall:  92.53%; FB1:  94.32 foundGuessed:  708\r\n",
      "          Library: precision:  88.97%; recall:  66.85%; FB1:  76.34 foundGuessed:  553\r\n",
      " Operating_System: precision:  80.63%; recall:  90.06%; FB1:  85.08 foundGuessed:  191\r\n",
      "User_Interface_Element: precision:  90.83%; recall:  92.49%; FB1:  91.65 foundGuessed:  949\r\n",
      "            Value: precision:  93.58%; recall:  85.43%; FB1:  89.32 foundGuessed:  639\r\n",
      "         Variable: precision:  85.05%; recall:  86.80%; FB1:  85.92 foundGuessed:  1144\r\n",
      "          Version: precision:  95.49%; recall:  90.66%; FB1:  93.01 foundGuessed:  244\r\n",
      "          Website: precision:  97.62%; recall:  77.36%; FB1:  86.32 foundGuessed:  84\r\n",
      "-----------------------------------\r\n",
      "now evaluating:  test\r\n",
      "-----------------------------------\r\n",
      "processed 45541 tokens with 3858 phrases; found: 3834 phrases; correct: 2806.\r\n",
      "accuracy:  97.38%; precision:  73.19%; recall:  72.73%; FB1:  72.96\r\n",
      "        Algorithm: precision:  33.33%; recall:   6.25%; FB1:  10.53 foundGuessed:  3\r\n",
      "      Application: precision:  68.05%; recall:  88.45%; FB1:  76.92 foundGuessed:  529\r\n",
      "            Class: precision:  69.50%; recall:  68.82%; FB1:  69.16 foundGuessed:  505\r\n",
      "       Code_Block: precision:  57.61%; recall:  58.94%; FB1:  58.27 foundGuessed:  309\r\n",
      "   Data_Structure: precision:  84.36%; recall:  83.00%; FB1:  83.67 foundGuessed:  243\r\n",
      "        Data_Type: precision:  82.76%; recall:  86.49%; FB1:  84.58 foundGuessed:  116\r\n",
      "           Device: precision:  69.09%; recall:  71.70%; FB1:  70.37 foundGuessed:  55\r\n",
      "        File_Name: precision:  86.08%; recall:  83.44%; FB1:  84.74 foundGuessed:  158\r\n",
      "        File_Type: precision:  86.24%; recall:  72.87%; FB1:  78.99 foundGuessed:  109\r\n",
      "         Function: precision:  76.21%; recall:  65.04%; FB1:  70.18 foundGuessed:  227\r\n",
      "     HTML_XML_Tag: precision:  64.44%; recall:  55.77%; FB1:  59.79 foundGuessed:  45\r\n",
      "         Language: precision:  85.03%; recall:  79.78%; FB1:  82.32 foundGuessed:  167\r\n",
      "          Library: precision:  74.85%; recall:  48.64%; FB1:  58.96 foundGuessed:  167\r\n",
      " Operating_System: precision:  78.21%; recall:  92.42%; FB1:  84.72 foundGuessed:  78\r\n",
      "User_Interface_Element: precision:  77.78%; recall:  80.85%; FB1:  79.28 foundGuessed:  369\r\n",
      "            Value: precision:  80.11%; recall:  68.35%; FB1:  73.76 foundGuessed:  186\r\n",
      "         Variable: precision:  60.14%; recall:  70.63%; FB1:  64.96 foundGuessed:  444\r\n",
      "          Version: precision:  91.35%; recall:  85.59%; FB1:  88.37 foundGuessed:  104\r\n",
      "          Website: precision:  95.00%; recall:  48.72%; FB1:  64.41 foundGuessed:  20\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\\begin{table}[htbp]\r\n",
      "\\centering\r\n",
      "\\begin{tabular}{|c|c|c|c|}\r\n",
      "\\hline\r\n",
      " & Precision & Recall & F1\\\\\r\n",
      "\\hline\r\n",
      "Class & 69.5 & 68.82 & 69.16\\\\\r\n",
      "Application & 68.05 & 88.45 & 76.92\\\\\r\n",
      "Variable & 60.14 & 70.63 & 64.96\\\\\r\n",
      "User Interface Element & 77.78 & 80.85 & 79.28\\\\\r\n",
      "Code Block & 57.61 & 58.94 & 58.27\\\\\r\n",
      "Function & 76.21 & 65.04 & 70.18\\\\\r\n",
      "Language & 85.03 & 79.78 & 82.32\\\\\r\n",
      "Library & 74.85 & 48.64 & 58.96\\\\\r\n",
      "Value & 80.11 & 68.35 & 73.76\\\\\r\n",
      "Data Structure & 84.36 & 83.0 & 83.67\\\\\r\n",
      "Data Type & 82.76 & 86.49 & 84.58\\\\\r\n",
      "File Type & 86.24 & 72.87 & 78.99\\\\\r\n",
      "File Name & 86.08 & 83.44 & 84.74\\\\\r\n",
      "Version & 91.35 & 85.59 & 88.37\\\\\r\n",
      "HTML XML Tag & 64.44 & 55.77 & 59.79\\\\\r\n",
      "Device & 69.09 & 71.7 & 70.37\\\\\r\n",
      "Operating System & 78.21 & 92.42 & 84.72\\\\\r\n",
      "Website & 95.0 & 48.72 & 64.41\\\\\r\n",
      "Algorithm & 33.33 & 6.25 & 10.53\\\\\r\n",
      "overall & 73.19 & 72.73 & 72.96\\\\\r\n",
      "\\hline\r\n",
      "\\end{tabular}\r\n",
      "\\caption{}\r\n",
      "\\end{table}\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "-----------------------------------\r\n",
      "time in this epoch:  21970.68362045288 secs\r\n",
      "total time in training:  51424.883888959885\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/root/Project/StackOverflowNER/code/Attentive_BiLSTM/')\n",
    "!cat running.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: epoch: 1 P: 70.58 R: 70.22 F1: 70.4\r\n",
      "test: epoch: 2 P: 74.94 R: 74.81 F1: 74.87\r\n",
      "test: epoch: 3 P: 73.19 R: 72.73 F1: 72.96\r\n"
     ]
    }
   ],
   "source": [
    "!cat perf_per_epoch_2020-10-19_9911_1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the original result from the paper. \n",
    "![paperSoftNER](./notebook_resources/paperSoftNER.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAoCF2YruZ1n",
    "nbpresent": {
     "id": "a607c108-2092-43cd-9bcd-2ac565bef1af"
    }
   },
   "source": [
    "## Extend the work\n",
    "Although, we still can not run reproduce the complete result from the original work because of the missing files. \n",
    "We still propose an idea to extend the work from the original paper. As the model is trained on StackOverflow, and we see some level of performance decrease while evaluating the model on Github README. So we would like to know for the reason of why the model only works well on StackOverflow. Therefore, we start from crawling the text corpus\n",
    "from [Leetcode](https://leetcode.com), as it shares strong similarity just like StackOverflow, with large part of code in the article piece.\n",
    "\n",
    "Here is the code example for how to use SoftNER to indentify named entities in article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Identify Named Entities \"\"\"\n",
    "\n",
    "os.chdir('/root/Project/StackOverflowNER/code/BERT_NER/')\n",
    "\n",
    "from utils_preprocess import *\n",
    "from utils_preprocess.format_markdown import *\n",
    "from utils_preprocess.anntoconll import *\n",
    "\n",
    "import glob\n",
    "\n",
    "from utils_ctc import *\n",
    "from utils_ctc.prediction_ctc import *\n",
    "\n",
    "import softner_segmenter_preditct_from_file\n",
    "import softner_ner_predict_from_fil\n",
    "\n",
    "from E2E_SoftNER import read_file, merge_all_conll_files, create_segmenter_input, create_ner_input\n",
    "\n",
    "\n",
    "# input file\n",
    "input_file = \"../../../leetcode-discuss.txt\"\n",
    "base_temp_dir = \"temp_files/\"\n",
    "standoff_folder = \"temp_files/standoff_files/\"\n",
    "# dir of code recognizer\n",
    "conll_folder = \"temp_files/conll_files/\"\n",
    "conll_file = \"temp_files/conll_format_txt.txt\"\n",
    "# dir of entity segmenter\n",
    "segmenter_input_file = \"temp_files/segmenter_ip.txt\"\n",
    "segmenter_output_file = \"temp_files/segemeter_preds.txt\"\n",
    "# input features & SoftNER prediction \n",
    "ner_input_file = \"temp_files/ner_ip.txt\"\n",
    "ner_output_file = \"ner_preds.txt\"\n",
    "\n",
    "if not os.path.exists(base_temp_dir): os.makedirs(base_temp_dir)\n",
    "if not os.path.exists(standoff_folder): os.makedirs(standoff_folder)\n",
    "if not os.path.exists(conlll_folder): os.makedirs(conlll_folder)\n",
    "\n",
    "# read sentences and tokenize the sentences\n",
    "read_file(input_file, standoff_folder)\n",
    "\n",
    "# Code Recognizer\n",
    "convert_standoff_to_conll(standoff_folder, conll_folder)\n",
    "merge_all_conll_files(conll_folder, conll_file)\n",
    "create_segmenter_input(conll_file, segmenter_input_file, ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features)\n",
    "\n",
    "# Entity Segmenter\n",
    "predict_segments(segmenter_input_file, segmenter_output_file)\n",
    "create_ner_input(segmenter_output_file, ner_input_file, ctc_classifier, vocab_size, word_to_id, id_to_word, word_to_vec, features)\n",
    "\n",
    "# recognize named entities\n",
    "softner_ner_predict_from_file.predict_entities(ner_input_file, ner_output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and Solutions\n",
    "\n",
    "<!-- challenges & solutions -->\n",
    "\n",
    "- The size of the dataset is more than 30G. The quote of Google drive API is limited when running codes on Colab.\n",
    "    - Set up an instance on Google Cloud\n",
    "    - Built a Jupyter server\n",
    "- Bugs in the source codes\n",
    "    - Encoding problem when read or write files\n",
    "    - Syntax errors\n",
    "    - Incompatible version of modules\n",
    "- Several essential files are missing in the original folder\n",
    "    - Contacted the author and requested the files. (Thank you Jeniya!)\n",
    "- Instruction to set up the model is not clear\n",
    "    - Code review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution\n",
    "\n",
    "<!-- Acknowledgement -->\n",
    "\n",
    "**Changheng Liou**\n",
    "- Build up a Jupyter server, which directs to the instance in Google Cloud\n",
    "- Crawling the sentences in Leetcode discussion\n",
    "- Analyze the SoftNER model architecture\n",
    "- Code review\n",
    "- Responsible for presenting our work in the final presentation\n",
    "- Complete the report\n",
    "\n",
    "**Zhiying Cui**\n",
    "- Provide a server in Google Cloud and set up the environment\n",
    "- Debug the source codes \n",
    "- Analyze the auxiliary models\n",
    "- Code review\n",
    "- Responsible for answering questions in the final presentation\n",
    "- Complete the report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMrS5Twng5Fs",
    "nbpresent": {
     "id": "e268745f-5723-4a9b-bab7-fa5c14569f97"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. Jeniya Tabassum et al., [Code and Named Entity Recognition in StackOverﬂow](https://arxiv.org/abs/2005.01634)\n",
    "2. Jacob Devlin et al., [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "3. [StackOverflowNER](https://github.com/jeniyat/StackOverflowNER)\n",
    "4. [Pre-trained BERTOverflow](https://huggingface.co/jeniya/BERTOverflow#)\n",
    "5. [BERT](https://huggingface.co/transformers/model_doc/bert.html)\n",
    "6. [transformers](https://github.com/huggingface/transformers)\n",
    "7. [fastText](https://github.com/facebookresearch/fastText)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
